{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b865b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import statistics\n",
    "import re\n",
    "from collections import Counter\n",
    "from openai import OpenAI, RateLimitError, APIError\n",
    "import time\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from load_llm_util import load_base_model_for_inference, load_fft_model_for_inference, load_lora_model_for_inference, load_qlora_model_for_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b80ea",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da0288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load API key securely from environment variable\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"Error: OPENAI_API_KEY environment variable not set.\")\n",
    "\n",
    "JUDGE_MODEL = \"gpt-4o\" # Or another powerful model like gpt-o1\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 5 # seconds\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a friendly college student chatbot. Respond naturally in Hinglish (mix of Romanized Hindi and English). Keep the conversation casual and engaging. Avoid being overly formal. Respond with followup questions to keep coversation engaging\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b443ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# EVALUATION PROMPTS\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "JUDGE_SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert evaluator assessing chatbot responses for a Hinglish‑speaking setting.\n",
    "\n",
    "**Primary objectives (carry the most weight):**\n",
    "1. **Hindi Usage** – Response should be *Hindi‑heavy Hinglish*:  \n",
    "   • At least 40‑60 % of the tokens should be Roman‑script Hindi words / phrases.  \n",
    "   • Pure English should be used sparingly and mostly for modern slang or technical terms.  \n",
    "   • Devanagari is acceptable only for short quotes or special emphasis.  \n",
    "2. **Gender Correctness** – Any gendered address (pronouns, verb forms, honorifics) **must match the user’s stated or obvious gender**.  \n",
    "   • If gender is not explicit, default to gender‑neutral Hinglish (“yaar”, “friend”, etc.).  \n",
    "   • Mis‑gendering or inconsistent switching is a serious error.\n",
    "\n",
    "**Secondary objectives (still score, but lower weight):**\n",
    "* **Hinglish Fluency** – Natural code‑switching, idiomatic phrasing.\n",
    "* **Persona Adherence** – Friendly college student vibe: informal, relatable, campus life references.\n",
    "* **Coherence** – Logical, on‑topic, internally consistent.\n",
    "* **Engagingness** – Keeps the conversation lively / interesting.\n",
    "* **Language Constraint** – Avoids pure English or pure Hindi blocks unless context demands.\n",
    "\n",
    "Use a 1‑5 Likert scale (1 = Poor, 5 = Excellent) for each metric.  \n",
    "Provide a concise justification (1‑2 sentences) for every score.\n",
    "\n",
    "Output **only** a valid JSON object with exactly these keys:\n",
    "\n",
    "- \"hindi_usage_score\": int (1‑5)\n",
    "- \"hindi_usage_justification\": str\n",
    "- \"gender_correctness_score\": int (1‑5)\n",
    "- \"gender_correctness_justification\": str\n",
    "- \"hinglish_fluency_score\": int (1‑5)\n",
    "- \"hinglish_fluency_justification\": str\n",
    "- \"persona_adherence_score\": int (1‑5)\n",
    "- \"persona_adherence_justification\": str\n",
    "- \"coherence_score\": int (1‑5)\n",
    "- \"coherence_justification\": str\n",
    "- \"engagingness_score\": int (1‑5)\n",
    "- \"engagingness_justification\": str\n",
    "- \"language_constraint_score\": int (1‑5)\n",
    "- \"language_constraint_justification\": str\n",
    "\"\"\"\n",
    "\n",
    "JUDGE_USER_PROMPT_TEMPLATE = \"\"\"\n",
    "User Prompt:\n",
    "\"{user_prompt}\"\n",
    "\n",
    "Chatbot Response:\n",
    "\"{chatbot_response}\"\n",
    "\n",
    "Evaluate the Chatbot Response based on the criteria outlined in the system prompt.  \n",
    "Output **only** the JSON object.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ff558",
   "metadata": {},
   "source": [
    "### Judge LLM - OpenAI 4o "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_evaluation(client, user_prompt, chatbot_response):\n",
    "    \"\"\"\n",
    "    Gets evaluation scores from the LLM judge.\n",
    "    Returns a dictionary with scores or None if an error occurs after retries.\n",
    "    \"\"\"\n",
    "    judge_user_prompt = JUDGE_USER_PROMPT_TEMPLATE.format(\n",
    "        user_prompt=user_prompt,\n",
    "        chatbot_response=chatbot_response\n",
    "    )\n",
    "\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=JUDGE_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": JUDGE_SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": judge_user_prompt}\n",
    "                ],\n",
    "                temperature=0.1, # Low temperature for consistent evaluation\n",
    "                response_format={\"type\": \"json_object\"} # Request JSON output directly\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            eval_data = json.loads(content)\n",
    "\n",
    "            # Basic validation of expected keys (add more checks if needed)\n",
    "            required_keys = [\n",
    "                \"hinglish_fluency_score\", \"persona_adherence_score\",\n",
    "                \"coherence_score\", \"engagingness_score\", \"language_constraint_score\"\n",
    "            ]\n",
    "            if all(key in eval_data for key in required_keys):\n",
    "                 return eval_data\n",
    "            else:\n",
    "                print(f\"Warning: LLM judge response missing required keys. Response: {content}\")\n",
    "                # Optionally treat this as an error and retry/return None\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from LLM judge (Attempt {attempt + 1}/{MAX_RETRIES}): {e}\")\n",
    "            print(f\"LLM raw response: {content}\")\n",
    "        except (RateLimitError, APIError) as e:\n",
    "            print(f\"OpenAI API error (Attempt {attempt + 1}/{MAX_RETRIES}): {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during LLM evaluation (Attempt {attempt + 1}/{MAX_RETRIES}): {e}\")\n",
    "\n",
    "        if attempt < MAX_RETRIES - 1:\n",
    "            print(f\"Retrying in {RETRY_DELAY} seconds...\")\n",
    "            time.sleep(RETRY_DELAY)\n",
    "        else:\n",
    "            print(\"Error: Max retries reached for LLM evaluation.\")\n",
    "            return None # Failed after retries\n",
    "\n",
    "    return None # Should not be reached, but added for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e1005",
   "metadata": {},
   "source": [
    "### Quantitative Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc0256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_response_length(response):\n",
    "    \"\"\"Calculates the number of words in the response.\"\"\"\n",
    "    return len(response.split())\n",
    "\n",
    "def calculate_repetition_rate(response: str, n: int = 3) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the repetition rate of n-grams.\n",
    "    Args:\n",
    "        response (str): The text response.\n",
    "        n (int): The size of the n-gram (e.g., 3 for trigrams).\n",
    "    Returns:\n",
    "        float: The ratio of repeated n-grams to total n-grams. Returns 0 if not enough n-grams.\n",
    "    \"\"\"\n",
    "    words = response.lower().split()\n",
    "    if len(words) < n:\n",
    "        return 0.0\n",
    "\n",
    "    ngrams = [' '.join(words[i:i+n]) for i in range(len(words) - n + 1)]\n",
    "    if not ngrams:\n",
    "        return 0.0\n",
    "\n",
    "    ngram_counts = Counter(ngrams)\n",
    "    repeated_ngrams = sum(1 for count in ngram_counts.values() if count > 1)\n",
    "\n",
    "    return repeated_ngrams / len(ngrams)\n",
    "\n",
    "def calculate_basic_code_switching(response: str, hindi_keywords: set, english_keywords: set) -> int:\n",
    "    \"\"\"\n",
    "    A very basic heuristic for counting potential code switches.\n",
    "    Counts transitions between likely English and likely Hindi words.\n",
    "    NOTE: This is highly approximate and prone to errors with Romanized text.\n",
    "    \"\"\"\n",
    "    words = re.findall(r'\\b\\w+\\b', response.lower())\n",
    "    if len(words) < 2:\n",
    "        return 0\n",
    "\n",
    "    switches = 0\n",
    "    current_lang = None\n",
    "\n",
    "    for word in words:\n",
    "        lang = None\n",
    "        if word in hindi_keywords:\n",
    "            lang = \"hindi\"\n",
    "        elif word in english_keywords:\n",
    "            lang = \"english\"\n",
    "        else: # (unknown word)\n",
    "            lang = None\n",
    "\n",
    "        if lang is not None:\n",
    "            if current_lang is not None and lang != current_lang:\n",
    "                switches += 1\n",
    "            current_lang = lang\n",
    "\n",
    "    return switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2fb796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions for Model Loading & Inference ---\n",
    "\n",
    "def generate_conversational_response(model, tokenizer, chat_history):\n",
    "    \"\"\"\n",
    "    Generates a response from the model based on the chat history.\n",
    "    Does not modify the input chat_history.\n",
    "    \"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    device = model.device\n",
    "\n",
    "    # Prepare the conversation history\n",
    "    formatted_history = []\n",
    "    if chat_history and chat_history[0].get(\"role\") != \"system\":\n",
    "         # Prepend the default system prompt if not present\n",
    "         formatted_history.append({\"role\": \"system\", \"content\": SYSTEM_PROMPT})\n",
    "    formatted_history.extend(chat_history)\n",
    "\n",
    "    try:\n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            formatted_history,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "        generation_kwargs = dict(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=50,      # Adjusted max tokens\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**generation_kwargs)\n",
    "\n",
    "        response_ids = outputs[0][input_ids.shape[-1]:]\n",
    "        response = tokenizer.decode(response_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during generation: {e}\")\n",
    "        response = \"Sorry yaar, kuch gadbad ho gayi generation mein. Dobara try karega?\" # Default error response\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a850a20b",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5eeeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    base_model_id: str,              # Base model ID\n",
    "    adapter_path: str | None,        # Path to the saved LoRA adapter directory\n",
    "    eval_prompts: list[str],         # Evaluations input promts list\n",
    "    model_name: str,                 # Name for this specific evaluated model/adapter\n",
    "    fine_tune_type: str | None       # Type : Base | LoRA | QLoRA | Full Fine tune\n",
    "    ) -> dict:\n",
    "    \"\"\"\n",
    "    Loads various models and evaluates it using LLM judge and quantitative metrics.\n",
    "\n",
    "    Args:\n",
    "        base_model_id: Identifier for the base model on Hugging Face Hub or local path.\n",
    "        adapter_path: Path to the directory containing the trained LoRA adapter files.\n",
    "        eval_prompts: A list of user prompts for evaluation.\n",
    "        model_name: A descriptive name for the model being evaluated (e.g., \"Qwen1.5B_Hinglish_v1\").\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing aggregated evaluation results.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Evaluation for Model: {model_name} ---\")\n",
    "    print(f\"--- Base: {base_model_id}, Adapter: {adapter_path} ---\")\n",
    "\n",
    "    if not OPENAI_API_KEY:\n",
    "         raise(\"Error: OpenAI API Key not configured. Cannot perform LLM evaluation.\")\n",
    "\n",
    "    # Initialize OpenAI Client (only if key is present)\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None\n",
    "\n",
    "    # Load Model and Tokenizer\n",
    "    try:\n",
    "        if fine_tune_type == \"LoRA\":\n",
    "            model, tokenizer = load_lora_model_for_inference(base_model_id, adapter_path, device='cuda')\n",
    "\n",
    "        elif fine_tune_type == \"QLoRA\":\n",
    "            model, tokenizer = load_qlora_model_for_inference(base_model_id, adapter_path, device='cuda')\n",
    "\n",
    "        elif fine_tune_type == \"base\":\n",
    "            model, tokenizer = load_base_model_for_inference(base_model_id, device='cuda')\n",
    "            \n",
    "        else:\n",
    "            model, tokenizer = load_fft_model_for_inference(base_model_id, device='cuda')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model {model_name}. Aborting evaluation for this model.\")\n",
    "        print(e)\n",
    "        return {\n",
    "            \"model_name\": model_name,\n",
    "            \"error\": f\"Model loading failed: {e}\",\n",
    "            \"per_prompt_details\": [],\n",
    "            \"aggregated_metrics\": {\"status\": \"Model Loading Failed\"}\n",
    "        }\n",
    "\n",
    "    # --- Evaluation Loop ---\n",
    "    all_results = {\n",
    "        \"model_name\": model_name,\n",
    "        \"base_model_id\": base_model_id,\n",
    "        \"adapter_path\": adapter_path,\n",
    "        \"per_prompt_details\": [],\n",
    "        \"aggregated_metrics\": {}\n",
    "    }\n",
    "\n",
    "    for i, prompt in enumerate(eval_prompts):\n",
    "        print(f\"  Processing prompt {i+1}/{len(eval_prompts)} for {model_name}...\")\n",
    "        try:\n",
    "            # 1. Prepare Chat History\n",
    "            chat_history = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "            # 2. Get Model Response\n",
    "            response_text = generate_conversational_response(model, tokenizer, chat_history)\n",
    "            if not response_text or not isinstance(response_text, str):\n",
    "                print(f\"  Warning: Invalid response received for prompt {i+1}. Using empty string.\")\n",
    "                response_text = \"\"\n",
    "\n",
    "            # 3. Calculate Quantitative Metrics\n",
    "            length = calculate_response_length(response_text)\n",
    "            repetition = calculate_repetition_rate(response_text)\n",
    "\n",
    "            # 4. Get LLM Judge Evaluation (if client is available)\n",
    "            llm_scores = None\n",
    "            if client:\n",
    "                llm_scores = get_llm_evaluation(client, prompt, response_text)\n",
    "            else:\n",
    "                llm_scores = \"Skipped (No API Key)\"\n",
    "\n",
    "\n",
    "            prompt_result = {\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": response_text,\n",
    "                \"length\": length,\n",
    "                \"repetition_rate_3gram\": repetition,\n",
    "                \"llm_evaluation\": llm_scores if llm_scores else \"Evaluation Failed or Skipped\"\n",
    "            }\n",
    "            all_results[\"per_prompt_details\"].append(prompt_result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing prompt {i+1} for {model_name}: {e}\")\n",
    "            all_results[\"per_prompt_details\"].append({\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": f\"Error during generation or processing: {e}\",\n",
    "                \"length\": 0,\n",
    "                \"repetition_rate_3gram\": 0.0,\n",
    "                \"llm_evaluation\": \"Processing Error\"\n",
    "            })\n",
    "\n",
    "    # --- Aggregation ---\n",
    "    valid_llm_evals = [\n",
    "        res[\"llm_evaluation\"] for res in all_results[\"per_prompt_details\"]\n",
    "        if isinstance(res[\"llm_evaluation\"], dict) # Only aggregate successful LLM evals\n",
    "    ]\n",
    "    num_successful_evals = len(valid_llm_evals)\n",
    "    num_total_prompts = len(eval_prompts)\n",
    "\n",
    "    aggregated = {\n",
    "        \"status\": \"Completed\",\n",
    "        \"total_prompts\": num_total_prompts,\n",
    "        \"successful_llm_evaluations\": num_successful_evals,\n",
    "        \"failed_or_skipped_llm_evaluations\": num_total_prompts - num_successful_evals,\n",
    "    }\n",
    "\n",
    "    # Aggregate LLM Scores (if any successful evaluations)\n",
    "    if num_successful_evals > 0:\n",
    "        for key in valid_llm_evals[0].keys():\n",
    "             if key.endswith(\"_score\"):\n",
    "                metric_name = key.replace(\"_score\", \"\")\n",
    "                # Ensure score is int/float before aggregating\n",
    "                scores = [eval_data[key] for eval_data in valid_llm_evals if isinstance(eval_data.get(key), (int, float))]\n",
    "                if scores:\n",
    "                    try:\n",
    "                        aggregated[f\"avg_{metric_name}_score\"] = statistics.mean(scores)\n",
    "                        aggregated[f\"stdev_{metric_name}_score\"] = statistics.stdev(scores) if len(scores) > 1 else 0.0\n",
    "                        aggregated[f\"median_{metric_name}_score\"] = statistics.median(scores)\n",
    "                    except statistics.StatisticsError as stat_err:\n",
    "                         print(f\"Warning: Statistics error for {metric_name}: {stat_err}\")\n",
    "                         aggregated[f\"avg_{metric_name}_score\"] = None\n",
    "                else:\n",
    "                     aggregated[f\"avg_{metric_name}_score\"] = None\n",
    "\n",
    "    # Aggregate Quantitative Metrics\n",
    "    lengths = [res[\"length\"] for res in all_results[\"per_prompt_details\"] if isinstance(res.get(\"length\"), (int, float))]\n",
    "    repetitions = [res[\"repetition_rate_3gram\"] for res in all_results[\"per_prompt_details\"] if isinstance(res.get(\"repetition_rate_3gram\"), (int, float))]\n",
    "\n",
    "    aggregated[\"avg_response_length\"] = statistics.mean(lengths) if lengths else 0\n",
    "    aggregated[\"avg_repetition_rate_3gram\"] = statistics.mean(repetitions) if repetitions else 0\n",
    "\n",
    "    all_results[\"aggregated_metrics\"] = aggregated\n",
    "\n",
    "    # --- Cleanup ---\n",
    "    print(f\"  Cleaning up resources for {model_name}...\")\n",
    "    del model\n",
    "    del tokenizer\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"--- Evaluation Complete for Model: {model_name} ---\")\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cde749",
   "metadata": {},
   "source": [
    "### Eval LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b98c72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Evaluation for Model: Qwen2.5-3B_Hinglish_base ---\n",
      "--- Base: Qwen/Qwen2.5-3B-Instruct, Adapter: None ---\n",
      "\n",
      "Loading Full Fine-Tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 52.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "  Processing prompt 1/10 for Qwen2.5-3B_Hinglish_base...\n",
      "  Processing prompt 2/10 for Qwen2.5-3B_Hinglish_base...\n",
      "  Processing prompt 3/10 for Qwen2.5-3B_Hinglish_base...\n",
      "  Processing prompt 4/10 for Qwen2.5-3B_Hinglish_base...\n",
      "  Processing prompt 5/10 for Qwen2.5-3B_Hinglish_base...\n",
      "  Processing prompt 6/10 for Qwen2.5-3B_Hinglish_base...\n",
      "  Processing prompt 7/10 for Qwen2.5-3B_Hinglish_base...\n",
      "  Processing prompt 8/10 for Qwen2.5-3B_Hinglish_base...\n",
      "  Processing prompt 9/10 for Qwen2.5-3B_Hinglish_base...\n",
      "  Processing prompt 10/10 for Qwen2.5-3B_Hinglish_base...\n",
      "  Cleaning up resources for Qwen2.5-3B_Hinglish_base...\n",
      "--- Evaluation Complete for Model: Qwen2.5-3B_Hinglish_base ---\n",
      "\n",
      "--- Starting Evaluation for Model: Qwen2.5-0.5B_Hinglish_FFT ---\n",
      "--- Base: ./Qwen2.5-0.5B-Instruct_hinglish_finetune/Qwen2.5-0.5B-Instruct/full_finetune, Adapter: None ---\n",
      "\n",
      "Loading Full Fine-Tuned model...\n",
      "Model loaded successfully!\n",
      "  Processing prompt 1/10 for Qwen2.5-0.5B_Hinglish_FFT...\n",
      "  Processing prompt 2/10 for Qwen2.5-0.5B_Hinglish_FFT...\n",
      "  Processing prompt 3/10 for Qwen2.5-0.5B_Hinglish_FFT...\n",
      "  Processing prompt 4/10 for Qwen2.5-0.5B_Hinglish_FFT...\n",
      "  Processing prompt 5/10 for Qwen2.5-0.5B_Hinglish_FFT...\n",
      "  Processing prompt 6/10 for Qwen2.5-0.5B_Hinglish_FFT...\n",
      "  Processing prompt 7/10 for Qwen2.5-0.5B_Hinglish_FFT...\n",
      "  Processing prompt 8/10 for Qwen2.5-0.5B_Hinglish_FFT...\n",
      "  Processing prompt 9/10 for Qwen2.5-0.5B_Hinglish_FFT...\n",
      "  Processing prompt 10/10 for Qwen2.5-0.5B_Hinglish_FFT...\n",
      "  Cleaning up resources for Qwen2.5-0.5B_Hinglish_FFT...\n",
      "--- Evaluation Complete for Model: Qwen2.5-0.5B_Hinglish_FFT ---\n",
      "\n",
      "--- Starting Evaluation for Model: Qwen2.5-3B_Hinglish_LoRA ---\n",
      "--- Base: Qwen/Qwen2.5-3B-Instruct, Adapter: ./Qwen2.5-3B-Instruct_hinglish_finetune/Qwen2.5-3B-Instruct/lora_finetune ---\n",
      "\n",
      "Loading LoRA-Qwen/Qwen2.5-3B-Instruct Fine-Tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 55.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading adapters from './Qwen2.5-3B-Instruct_hinglish_finetune/Qwen2.5-3B-Instruct/lora_finetune'...\n",
      "Model loaded successfully!\n",
      "  Processing prompt 1/10 for Qwen2.5-3B_Hinglish_LoRA...\n",
      "  Processing prompt 2/10 for Qwen2.5-3B_Hinglish_LoRA...\n",
      "  Processing prompt 3/10 for Qwen2.5-3B_Hinglish_LoRA...\n",
      "  Processing prompt 4/10 for Qwen2.5-3B_Hinglish_LoRA...\n",
      "  Processing prompt 5/10 for Qwen2.5-3B_Hinglish_LoRA...\n",
      "  Processing prompt 6/10 for Qwen2.5-3B_Hinglish_LoRA...\n",
      "  Processing prompt 7/10 for Qwen2.5-3B_Hinglish_LoRA...\n",
      "  Processing prompt 8/10 for Qwen2.5-3B_Hinglish_LoRA...\n",
      "  Processing prompt 9/10 for Qwen2.5-3B_Hinglish_LoRA...\n",
      "  Processing prompt 10/10 for Qwen2.5-3B_Hinglish_LoRA...\n",
      "  Cleaning up resources for Qwen2.5-3B_Hinglish_LoRA...\n",
      "--- Evaluation Complete for Model: Qwen2.5-3B_Hinglish_LoRA ---\n",
      "\n",
      "--- Starting Evaluation for Model: Qwen2.5-3B_Hinglish_QLoRA ---\n",
      "--- Base: Qwen/Qwen2.5-3B-Instruct, Adapter: ./Qwen2.5-3B-Instruct_hinglish_finetune/Qwen2.5-3B-Instruct/qlora_finetune ---\n",
      "\n",
      "Loading QLoRA-Qwen/Qwen2.5-3B-Instruct Fine-Tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading adapters from './Qwen2.5-3B-Instruct_hinglish_finetune/Qwen2.5-3B-Instruct/qlora_finetune'...\n",
      "Model loaded successfully!\n",
      "  Processing prompt 1/10 for Qwen2.5-3B_Hinglish_QLoRA...\n",
      "  Processing prompt 2/10 for Qwen2.5-3B_Hinglish_QLoRA...\n",
      "  Processing prompt 3/10 for Qwen2.5-3B_Hinglish_QLoRA...\n",
      "  Processing prompt 4/10 for Qwen2.5-3B_Hinglish_QLoRA...\n",
      "  Processing prompt 5/10 for Qwen2.5-3B_Hinglish_QLoRA...\n",
      "  Processing prompt 6/10 for Qwen2.5-3B_Hinglish_QLoRA...\n",
      "  Processing prompt 7/10 for Qwen2.5-3B_Hinglish_QLoRA...\n",
      "  Processing prompt 8/10 for Qwen2.5-3B_Hinglish_QLoRA...\n",
      "  Processing prompt 9/10 for Qwen2.5-3B_Hinglish_QLoRA...\n",
      "  Processing prompt 10/10 for Qwen2.5-3B_Hinglish_QLoRA...\n",
      "  Cleaning up resources for Qwen2.5-3B_Hinglish_QLoRA...\n",
      "--- Evaluation Complete for Model: Qwen2.5-3B_Hinglish_QLoRA ---\n",
      "\n",
      "\n",
      "============================================================\n",
      "          Evaluation Summary\n",
      "============================================================\n",
      "\n",
      "Model: Qwen2.5-3B_Hinglish_base\n",
      "  Status: Completed\n",
      "  Aggregated Metrics:\n",
      "    total_prompts: 10\n",
      "    successful_llm_evaluations: 10\n",
      "    failed_or_skipped_llm_evaluations: 0\n",
      "    avg_hindi_usage_score: 3.300\n",
      "    stdev_hindi_usage_score: 1.636\n",
      "    median_hindi_usage_score: 4.000\n",
      "    avg_gender_correctness_score: 4.400\n",
      "    stdev_gender_correctness_score: 0.966\n",
      "    median_gender_correctness_score: 5.000\n",
      "    avg_hinglish_fluency_score: 2.700\n",
      "    stdev_hinglish_fluency_score: 1.337\n",
      "    median_hinglish_fluency_score: 3.000\n",
      "    avg_persona_adherence_score: 3.200\n",
      "    stdev_persona_adherence_score: 0.789\n",
      "    median_persona_adherence_score: 3.000\n",
      "    avg_coherence_score: 3.300\n",
      "    stdev_coherence_score: 1.252\n",
      "    median_coherence_score: 3.500\n",
      "    avg_engagingness_score: 2.600\n",
      "    stdev_engagingness_score: 0.843\n",
      "    median_engagingness_score: 2.000\n",
      "    avg_language_constraint_score: 3.400\n",
      "    stdev_language_constraint_score: 1.506\n",
      "    median_language_constraint_score: 4.000\n",
      "    avg_response_length: 31.700\n",
      "    avg_repetition_rate_3gram: 0.000\n",
      "\n",
      "Model: Qwen2.5-0.5B_Hinglish_FFT\n",
      "  Status: Completed\n",
      "  Aggregated Metrics:\n",
      "    total_prompts: 10\n",
      "    successful_llm_evaluations: 10\n",
      "    failed_or_skipped_llm_evaluations: 0\n",
      "    avg_hindi_usage_score: 3.400\n",
      "    stdev_hindi_usage_score: 0.699\n",
      "    median_hindi_usage_score: 3.500\n",
      "    avg_gender_correctness_score: 4.700\n",
      "    stdev_gender_correctness_score: 0.675\n",
      "    median_gender_correctness_score: 5.000\n",
      "    avg_hinglish_fluency_score: 3.200\n",
      "    stdev_hinglish_fluency_score: 1.317\n",
      "    median_hinglish_fluency_score: 3.000\n",
      "    avg_persona_adherence_score: 3.300\n",
      "    stdev_persona_adherence_score: 1.252\n",
      "    median_persona_adherence_score: 3.500\n",
      "    avg_coherence_score: 2.700\n",
      "    stdev_coherence_score: 1.567\n",
      "    median_coherence_score: 2.500\n",
      "    avg_engagingness_score: 2.500\n",
      "    stdev_engagingness_score: 1.269\n",
      "    median_engagingness_score: 2.500\n",
      "    avg_language_constraint_score: 3.700\n",
      "    stdev_language_constraint_score: 0.823\n",
      "    median_language_constraint_score: 3.500\n",
      "    avg_response_length: 29\n",
      "    avg_repetition_rate_3gram: 0.000\n",
      "\n",
      "Model: Qwen2.5-3B_Hinglish_LoRA\n",
      "  Status: Completed\n",
      "  Aggregated Metrics:\n",
      "    total_prompts: 10\n",
      "    successful_llm_evaluations: 10\n",
      "    failed_or_skipped_llm_evaluations: 0\n",
      "    avg_hindi_usage_score: 4\n",
      "    stdev_hindi_usage_score: 0.816\n",
      "    median_hindi_usage_score: 4.000\n",
      "    avg_gender_correctness_score: 4.900\n",
      "    stdev_gender_correctness_score: 0.316\n",
      "    median_gender_correctness_score: 5.000\n",
      "    avg_hinglish_fluency_score: 4.200\n",
      "    stdev_hinglish_fluency_score: 0.632\n",
      "    median_hinglish_fluency_score: 4.000\n",
      "    avg_persona_adherence_score: 4.300\n",
      "    stdev_persona_adherence_score: 0.483\n",
      "    median_persona_adherence_score: 4.000\n",
      "    avg_coherence_score: 3.900\n",
      "    stdev_coherence_score: 0.738\n",
      "    median_coherence_score: 4.000\n",
      "    avg_engagingness_score: 3.700\n",
      "    stdev_engagingness_score: 0.675\n",
      "    median_engagingness_score: 4.000\n",
      "    avg_language_constraint_score: 4.300\n",
      "    stdev_language_constraint_score: 0.949\n",
      "    median_language_constraint_score: 5.000\n",
      "    avg_response_length: 30.600\n",
      "    avg_repetition_rate_3gram: 0.000\n",
      "\n",
      "Model: Qwen2.5-3B_Hinglish_QLoRA\n",
      "  Status: Completed\n",
      "  Aggregated Metrics:\n",
      "    total_prompts: 10\n",
      "    successful_llm_evaluations: 10\n",
      "    failed_or_skipped_llm_evaluations: 0\n",
      "    avg_hindi_usage_score: 3.800\n",
      "    stdev_hindi_usage_score: 1.317\n",
      "    median_hindi_usage_score: 4.000\n",
      "    avg_gender_correctness_score: 5\n",
      "    stdev_gender_correctness_score: 0.000\n",
      "    median_gender_correctness_score: 5.000\n",
      "    avg_hinglish_fluency_score: 4.300\n",
      "    stdev_hinglish_fluency_score: 1.337\n",
      "    median_hinglish_fluency_score: 5.000\n",
      "    avg_persona_adherence_score: 4.500\n",
      "    stdev_persona_adherence_score: 0.707\n",
      "    median_persona_adherence_score: 5.000\n",
      "    avg_coherence_score: 4.500\n",
      "    stdev_coherence_score: 0.707\n",
      "    median_coherence_score: 5.000\n",
      "    avg_engagingness_score: 4.100\n",
      "    stdev_engagingness_score: 0.568\n",
      "    median_engagingness_score: 4.000\n",
      "    avg_language_constraint_score: 4.500\n",
      "    stdev_language_constraint_score: 1.080\n",
      "    median_language_constraint_score: 5.000\n",
      "    avg_response_length: 29.500\n",
      "    avg_repetition_rate_3gram: 0.000\n",
      "\n",
      "============================================================\n",
      "Full evaluation results saved to evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "# Define your evaluation prompts\n",
    "evaluation_prompts = [\n",
    "    \"Hey kaise ho? College mein kya chal raha hai aajkal?\",\n",
    "    \"Yaar assignments ka bohot tension hai. Kuch tips?\",\n",
    "    \"Suggest some cool places to hangout near campus.\",\n",
    "    \"What did you think of the canteen food today?\",\n",
    "    \"Exams aa rahe hain, dar lag raha hai bhai.\",\n",
    "    \"Kal ka lecture attend kiya ya bunk maar diya?\",\n",
    "    \"Hostel ki light firse chali gayi kya?\",\n",
    "    \"Tu fest ke liye audition de raha hai kya?\",\n",
    "    \"Kya placement ka kuch update mila?\",\n",
    "    \"Online classes bore kar rahe hain, koi escape idea?\"\n",
    "]\n",
    "\n",
    "# === Define Models to Evaluate ===\n",
    "models_to_evaluate = [\n",
    "    {\n",
    "        \"model_name\": \"Qwen2.5-3B_Hinglish_base\",\n",
    "        \"base_model_id\": \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "        \"adapter_path\": None,\n",
    "        \"fine_tune_type\" : \"base\"\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"Qwen2.5-0.5B_Hinglish_FFT\",\n",
    "        \"base_model_id\": \"./Qwen2.5-0.5B-Instruct_hinglish_finetune/Qwen2.5-0.5B-Instruct/full_finetune\",\n",
    "        \"adapter_path\": None,\n",
    "        \"fine_tune_type\": \"FFT\"\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"Qwen2.5-3B_Hinglish_LoRA\",\n",
    "        \"base_model_id\": \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "        \"adapter_path\": \"./Qwen2.5-3B-Instruct_hinglish_finetune/Qwen2.5-3B-Instruct/lora_finetune\",\n",
    "        \"fine_tune_type\": \"LoRA\"\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"Qwen2.5-3B_Hinglish_QLoRA\",\n",
    "        \"base_model_id\": \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "        \"adapter_path\": \"./Qwen2.5-3B-Instruct_hinglish_finetune/Qwen2.5-3B-Instruct/qlora_finetune\",\n",
    "        \"fine_tune_type\": \"QLoRA\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# === Run Evaluation Loop ===\n",
    "all_evaluation_results = {}\n",
    "\n",
    "for model_info in models_to_evaluate:\n",
    "\n",
    "    results = evaluate_model(\n",
    "        base_model_id=model_info[\"base_model_id\"],\n",
    "        adapter_path=model_info[\"adapter_path\"],\n",
    "        eval_prompts=evaluation_prompts,\n",
    "        model_name=model_info[\"model_name\"],\n",
    "        fine_tune_type=model_info[\"fine_tune_type\"]\n",
    "    )\n",
    "    all_evaluation_results[model_info[\"model_name\"]] = results\n",
    "\n",
    "\n",
    "# --- Print Summary of Results ---\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"          Evaluation Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, results in all_evaluation_results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    if \"error\" in results:\n",
    "        print(f\"  Status: Error - {results.get('status', 'Unknown Error')}\")\n",
    "        print(f\"  Details: {results['error']}\")\n",
    "    elif \"aggregated_metrics\" in results:\n",
    "        print(f\"  Status: {results['aggregated_metrics'].get('status', 'Unknown')}\")\n",
    "        print(f\"  Aggregated Metrics:\")\n",
    "        for key, value in results[\"aggregated_metrics\"].items():\n",
    "            if key != \"status\": # Don't print status twice\n",
    "                # Format floats for readability\n",
    "                if isinstance(value, float):\n",
    "                    print(f\"    {key}: {value:.3f}\")\n",
    "                else:\n",
    "                    print(f\"    {key}: {value}\")\n",
    "    else:\n",
    "            print(\"  Status: Unknown - No aggregated metrics found.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Dump full `all_evaluation_results` dictionary to a JSON file\n",
    "with open(\"evaluation_results.json\", \"w\") as f:\n",
    "    json.dump(all_evaluation_results, f, indent=2)\n",
    "print(\"Full evaluation results saved to evaluation_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4bfb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_table(evaluation_results):\n",
    "    \"\"\"\n",
    "    Creates a comparison table from the evaluation results dictionary,\n",
    "    including percentage improvement over the base model.\n",
    "\n",
    "    Args:\n",
    "        evaluation_results: The dictionary containing results for multiple models.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the comparison table, ready for display\n",
    "        in Jupyter, or None if no valid results are found.\n",
    "    \"\"\"\n",
    "    table_data = []\n",
    "\n",
    "    base_metric_keys = [\n",
    "        \"avg_hinglish_fluency_score\",\n",
    "        \"avg_persona_adherence_score\",\n",
    "        \"avg_coherence_score\",\n",
    "        \"avg_engagingness_score\",\n",
    "        \"avg_language_constraint_score\",\n",
    "        \"avg_gender_correctness_score\",\n",
    "        \"avg_hindi_usage_score\",\n",
    "        \"avg_response_length\",\n",
    "        \"avg_repetition_rate_3gram\",\n",
    "        \"successful_llm_evaluations\",\n",
    "        \"total_prompts\",\n",
    "    ]\n",
    "\n",
    "    column_names = {\n",
    "        \"model_name\": \"Model\",\n",
    "        \"eval_type\": \"Type\",\n",
    "        \"avg_hinglish_fluency_score\": \"Avg Hinglish Fluency\",\n",
    "        \"avg_persona_adherence_score\": \"Avg Persona Adherence\",\n",
    "        \"avg_gender_correctness_score\": \"Avg Gender Correctness\",\n",
    "        \"avg_hindi_usage_score\": \"Avg Hindi Usage\",\n",
    "        \"avg_coherence_score\": \"Avg Coherence\",\n",
    "        \"avg_engagingness_score\": \"Avg Engagingness\",\n",
    "        \"avg_language_constraint_score\": \"Avg Lang Constraint\",\n",
    "        \"avg_response_length\": \"Avg Length (words)\",\n",
    "        \"avg_repetition_rate_3gram\": \"Avg Repetition (3-gram)\",\n",
    "        \"successful_llm_evaluations\": \"Successful Evals\",\n",
    "        \"total_prompts\": \"Total Prompts\",\n",
    "    }\n",
    "\n",
    "    # --- 1. Extract Base Data and Identify Base Model ---\n",
    "    base_model_metrics = all_evaluation_results[\"Qwen2.5-3B_Hinglish_base\"]['aggregated_metrics']\n",
    "    base_model_name = \"Qwen2.5-3B_Hinglish_base\"\n",
    "    processed_results = []\n",
    "\n",
    "    for model_name, result in evaluation_results.items():\n",
    "        # Standardize result structure\n",
    "        processed_row = {\n",
    "            \"model_name\": result.get(\"model_name\", model_name),\n",
    "            \"eval_type\": result.get(\"eval_type\", \"N/A\")\n",
    "        }\n",
    "        metrics = result.get(\"aggregated_metrics\", {})\n",
    "        status = metrics.get(\"status\", \"Unknown\")\n",
    "        processed_row[\"status\"] = status\n",
    "\n",
    "        if status == \"Completed\":\n",
    "            for key in base_metric_keys:\n",
    "                processed_row[key] = metrics.get(key)\n",
    "            processed_results.append(processed_row)\n",
    "\n",
    "            if processed_row[\"eval_type\"] == \"Base Model\":\n",
    "                if base_model_metrics is not None:\n",
    "                    print(\"Warning: Multiple base models found in results. Using the first one.\")\n",
    "                else:\n",
    "                    base_model_metrics = processed_row\n",
    "                    base_model_name = processed_row[\"model_name\"]\n",
    "        else:\n",
    "            processed_row.update({key: \"Failed\" for key in base_metric_keys})\n",
    "            processed_results.append(processed_row)\n",
    "\n",
    "    if not processed_results:\n",
    "        print(\"No evaluation results found to create a table.\")\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(processed_results)\n",
    "    df_completed = df[df['status'] == 'Completed'].copy()\n",
    "\n",
    "    # --- 2. Calculate Percentage Improvement ---\n",
    "    if base_model_metrics is None:\n",
    "        print(\"Warning: Base model results not found or failed. Cannot calculate % improvement.\")\n",
    "    else:\n",
    "        print(f\"Calculating % improvement relative to base model: '{base_model_name}'\")\n",
    "        # Metrics where higher score is better\n",
    "        metrics_higher_better = {\n",
    "            \"avg_hinglish_fluency_score\": \"Hinglish Fluency % Imp\",\n",
    "            \"avg_persona_adherence_score\": \"Persona Adherence % Imp\",\n",
    "            \"avg_gender_correctness_score\": \"Gender Correctness % Imp\",\n",
    "            \"avg_hindi_usage_score\": \"Hindi Usage % Imp\",\n",
    "            \"avg_coherence_score\": \"Coherence % Imp\",\n",
    "            \"avg_engagingness_score\": \"Engagingness % Imp\",\n",
    "            \"avg_language_constraint_score\": \"Lang Constraint % Imp\",\n",
    "        }\n",
    "        # Metrics where lower score is better\n",
    "        metrics_lower_better = {\n",
    "            \"avg_repetition_rate_3gram\": \"Repetition % Imp (Lower Better)\"\n",
    "        }\n",
    "\n",
    "        def calculate_improvement(adapter_val, base_val, lower_is_better=False):\n",
    "            adapter_val = pd.to_numeric(adapter_val, errors='coerce')\n",
    "            base_val = pd.to_numeric(base_val, errors='coerce')\n",
    "\n",
    "            if pd.isna(adapter_val) or pd.isna(base_val):\n",
    "                return np.nan\n",
    "            if base_val == 0:\n",
    "                if adapter_val == 0:\n",
    "                    return 0.0\n",
    "                return np.inf if not lower_is_better and adapter_val > 0 else (-np.inf if lower_is_better and adapter_val > 0 else np.nan)\n",
    "\n",
    "            if lower_is_better:\n",
    "                return ((base_val - adapter_val) / abs(base_val)) * 100\n",
    "            else:\n",
    "                return ((adapter_val - base_val) / abs(base_val)) * 100\n",
    "\n",
    "        for metric_key, imp_col_name in metrics_higher_better.items():\n",
    "            base_val = base_model_metrics.get(metric_key)\n",
    "            df_completed[imp_col_name] = df_completed.apply(\n",
    "                lambda row: calculate_improvement(row[metric_key], base_val, lower_is_better=False)\n",
    "                            if row[\"model_name\"] != base_model_name else np.nan,\n",
    "                axis=1\n",
    "            )\n",
    "            column_names[imp_col_name] = imp_col_name\n",
    "\n",
    "        for metric_key, imp_col_name in metrics_lower_better.items():\n",
    "            base_val = base_model_metrics.get(metric_key)\n",
    "            df_completed[imp_col_name] = df_completed.apply(\n",
    "                lambda row: calculate_improvement(row[metric_key], base_val, lower_is_better=True)\n",
    "                            if row[\"model_name\"] != base_model_name else np.nan,\n",
    "                axis=1\n",
    "            )\n",
    "            column_names[imp_col_name] = imp_col_name\n",
    "\n",
    "        improvement_cols = list(metrics_higher_better.values()) + list(metrics_lower_better.values())\n",
    "        df_improvements = df_completed[['model_name'] + improvement_cols]\n",
    "        df = pd.merge(df, df_improvements, on='model_name', how='left')\n",
    "\n",
    "    # --- 3. Final Table Formatting ---\n",
    "    df.rename(columns=column_names, inplace=True)\n",
    "\n",
    "    desired_column_order = [\n",
    "        \"Model\", \"Type\",\n",
    "        \"Avg Hinglish Fluency\", \"Hinglish Fluency % Imp\",\n",
    "        \"Avg Persona Adherence\", \"Persona Adherence % Imp\",\n",
    "        \"Avg Gender Correctness\", \"Gender Correctness % Imp\",\n",
    "        \"Avg Hindi Usage\", \"Hindi Usage % Imp\",\n",
    "        \"Avg Coherence\", \"Coherence % Imp\",\n",
    "        \"Avg Engagingness\", \"Engagingness % Imp\",\n",
    "        \"Avg Lang Constraint\", \"Lang Constraint % Imp\",\n",
    "        \"Avg Length (words)\",\n",
    "        \"Avg Repetition (3-gram)\", \"Repetition % Imp (Lower Better)\",\n",
    "        \"Successful Evals\", \"Total Prompts\",\n",
    "    ]\n",
    "    existing_desired_columns = [col for col in desired_column_order if col in df.columns]\n",
    "    df = df[existing_desired_columns]\n",
    "\n",
    "    df.set_index(\"Model\", inplace=True)\n",
    "\n",
    "    styled_df = df.style\n",
    "    float_cols = df.select_dtypes(include=['float']).columns\n",
    "    float_format_dict = {col: '{:.2f}' for col in float_cols if '% Imp' not in col}\n",
    "    percent_cols = [col for col in df.columns if '% Imp' in col]\n",
    "    percent_format_dict = {col: '{:+.1f}%' for col in percent_cols}\n",
    "    formatters = {**float_format_dict, **percent_format_dict}\n",
    "    styled_df = styled_df.format(formatters, na_rep=\"N/A\")\n",
    "\n",
    "    return styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41cad38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Qwen2.5-3B_Hinglish_base': {'model_name': 'Qwen2.5-3B_Hinglish_base',\n",
       "  'base_model_id': 'Qwen/Qwen2.5-3B-Instruct',\n",
       "  'adapter_path': None,\n",
       "  'per_prompt_details': [{'prompt': 'Hey kaise ho? College mein kya chal raha hai aajkal?',\n",
       "    'response': 'Hey! Kya aapne college se pehle khelna chahiye? Aaj main apni class mein hai, yeh sab samay hota hai. Kuch ghar mein phirse zyada relax kar',\n",
       "    'length': 26,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"Response uses a good mix of Hindi and Hinglish, but some phrases like 'khelna chahiye' seem out of context.\",\n",
       "     'gender_correctness_score': 3,\n",
       "     'gender_correctness_justification': \"The response uses 'aapne' which is formal and doesn't match the informal tone of the user's prompt.\",\n",
       "     'hinglish_fluency_score': 3,\n",
       "     'hinglish_fluency_justification': \"The code-switching is somewhat awkward, especially with phrases like 'yeh sab samay hota hai'.\",\n",
       "     'persona_adherence_score': 3,\n",
       "     'persona_adherence_justification': 'The response lacks the friendly, relatable college student vibe and feels slightly disjointed.',\n",
       "     'coherence_score': 2,\n",
       "     'coherence_justification': 'The response is not very coherent; it jumps from playing before college to being in class without clear connections.',\n",
       "     'engagingness_score': 2,\n",
       "     'engagingness_justification': 'The response is not very engaging due to its lack of coherence and relatable content.',\n",
       "     'language_constraint_score': 4,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a Hinglish mix.'}},\n",
       "   {'prompt': 'Yaar assignments ka bohot tension hai. Kuch tips?',\n",
       "    'response': 'Tension about assignments, yaar? Bhai, maine yeh bhi ek baar laga tha. Toh tu kuch simple tricks likho: Time table bnao, important topics first jaao, aur regular revision kar',\n",
       "    'length': 29,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 5,\n",
       "     'hindi_usage_justification': 'The response uses a good mix of Hindi and English, with Hindi being the dominant language, fulfilling the Hindi-heavy Hinglish requirement.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The user is addressed with 'yaar' and 'bhai', which are gender-neutral and appropriate for the context.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The code-switching is natural and idiomatic, fitting well with the Hinglish style.',\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly, relatable college student vibe with informal language and practical advice.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': \"The response is logical and directly addresses the user's concern with relevant tips.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is helpful and maintains interest, though it could be slightly more lively.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}},\n",
       "   {'prompt': 'Suggest some cool places to hangout near campus.',\n",
       "    'response': \"Hey there! Near your campus, there are several spots that could be fun to hang out at. One popular place is the Student Union building. It's like a mini-mall where you can grab snacks, have a coffee, and maybe even find\",\n",
       "    'length': 41,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 1,\n",
       "     'hindi_usage_justification': 'The response is almost entirely in English, with no Roman-script Hindi words or phrases.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral language, addressing the user as 'there'.\",\n",
       "     'hinglish_fluency_score': 1,\n",
       "     'hinglish_fluency_justification': 'The response lacks any Hinglish fluency, as it is entirely in English.',\n",
       "     'persona_adherence_score': 3,\n",
       "     'persona_adherence_justification': 'The response is somewhat friendly and relatable, but lacks specific campus life references.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': 'The response is coherent and on-topic, suggesting a place to hang out near campus.',\n",
       "     'engagingness_score': 2,\n",
       "     'engagingness_justification': 'The response is somewhat engaging but lacks lively or interesting details.',\n",
       "     'language_constraint_score': 1,\n",
       "     'language_constraint_justification': 'The response is in pure English, which does not meet the language constraint for a Hinglish setting.'}},\n",
       "   {'prompt': 'What did you think of the canteen food today?',\n",
       "    'response': \"Oh, the canteen food was alright! I usually love their veg biryani, but today they had something different and it wasn't as tasty as usual. What about you? Was there any particular dish you enjoyed or didn't enjoy today\",\n",
       "    'length': 39,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 1,\n",
       "     'hindi_usage_justification': 'The response is entirely in English, lacking any Hindi words or phrases.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender information.',\n",
       "     'hinglish_fluency_score': 1,\n",
       "     'hinglish_fluency_justification': 'There is no code-switching or use of Hinglish; the response is purely in English.',\n",
       "     'persona_adherence_score': 3,\n",
       "     'persona_adherence_justification': 'The response is friendly and informal, but lacks specific college life references.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': \"The response is logical and directly addresses the user's question about canteen food.\",\n",
       "     'engagingness_score': 3,\n",
       "     'engagingness_justification': 'The response is somewhat engaging by asking a follow-up question, but could be more lively.',\n",
       "     'language_constraint_score': 1,\n",
       "     'language_constraint_justification': 'The response fails to meet the language constraint as it is entirely in English.'}},\n",
       "   {'prompt': 'Exams aa rahe hain, dar lag raha hai bhai.',\n",
       "    'response': 'Aapki ek jyada exam ki karozi pad gayi! Kuch dhyan rakhenge par aapko kya advice dijiye? Doubt ke liye help karna main acha laga. Baki',\n",
       "    'length': 25,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"Response uses a good mix of Hindi and Hinglish, but some phrases like 'karozi pad gayi' seem awkward.\",\n",
       "     'gender_correctness_score': 3,\n",
       "     'gender_correctness_justification': \"The user used 'bhai', suggesting a male gender, but the response uses 'aapki', which is gender-neutral but slightly formal.\",\n",
       "     'hinglish_fluency_score': 3,\n",
       "     'hinglish_fluency_justification': 'The Hinglish is somewhat natural, but certain phrases are awkward and disrupt the flow.',\n",
       "     'persona_adherence_score': 3,\n",
       "     'persona_adherence_justification': 'The response is friendly but lacks the informal, relatable college student vibe.',\n",
       "     'coherence_score': 2,\n",
       "     'coherence_justification': 'The response is somewhat disjointed and lacks a clear, logical flow.',\n",
       "     'engagingness_score': 2,\n",
       "     'engagingness_justification': \"The response is not very engaging or lively, missing opportunities to connect with the user's concerns.\",\n",
       "     'language_constraint_score': 4,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a Hinglish mix.'}},\n",
       "   {'prompt': 'Kal ka lecture attend kiya ya bunk maar diya?',\n",
       "    'response': 'Baat main baat kar raha hoon, apne aap kahan tak reach huye? Kal ka lecture attend kiya ya bunk maar diya? Haan, apne samay pe yeh bhi zyada important',\n",
       "    'length': 29,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"Response uses a good mix of Hindi and Hinglish, with phrases like 'baat main baat kar raha hoon' and 'apne samay pe yeh bhi zyada important'.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral language, which is appropriate as the user's gender is not specified.\",\n",
       "     'hinglish_fluency_score': 3,\n",
       "     'hinglish_fluency_justification': \"The response is somewhat awkward with phrases like 'baat main baat kar raha hoon', which affects the natural flow.\",\n",
       "     'persona_adherence_score': 3,\n",
       "     'persona_adherence_justification': 'The response is friendly but lacks the informal, relatable college student vibe and campus life references.',\n",
       "     'coherence_score': 2,\n",
       "     'coherence_justification': \"The response is somewhat disjointed and doesn't directly address the user's question about attending the lecture.\",\n",
       "     'engagingness_score': 2,\n",
       "     'engagingness_justification': \"The response is not very engaging or lively, as it repeats the user's question without adding new information.\",\n",
       "     'language_constraint_score': 4,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a Hinglish style throughout.'}},\n",
       "   {'prompt': 'Hostel ki light firse chali gayi kya?',\n",
       "    'response': 'Light pehle nahi chal jati, kyunki hum hostel mein diye the lights baad mai! Iska kya karna tha? Aur hostel mein phirse light se kaise bahut important hai?',\n",
       "    'length': 28,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': 'Response uses a good mix of Hindi and English, but some phrases are awkwardly constructed.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender information.',\n",
       "     'hinglish_fluency_score': 3,\n",
       "     'hinglish_fluency_justification': 'The Hinglish is somewhat awkward and lacks natural flow, with some phrases not making complete sense.',\n",
       "     'persona_adherence_score': 3,\n",
       "     'persona_adherence_justification': 'The response is informal but lacks the relatable and friendly college student vibe.',\n",
       "     'coherence_score': 2,\n",
       "     'coherence_justification': \"The response is confusing and does not logically address the user's question about the power outage.\",\n",
       "     'engagingness_score': 2,\n",
       "     'engagingness_justification': 'The response is not very engaging due to its lack of clarity and relevance.',\n",
       "     'language_constraint_score': 4,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, but the language use is not entirely effective.'}},\n",
       "   {'prompt': 'Tu fest ke liye audition de raha hai kya?',\n",
       "    'response': 'Haan, ek baar mera naam dijiye na? Waise toh phir se kuch aur festes mein audition karne ki zaroorat ho skti hai. Kisi festival ka na?\\nHo sakta hai,',\n",
       "    'length': 29,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': 'Response uses a good mix of Hindi and English, with Hindi being the dominant language.',\n",
       "     'gender_correctness_score': 3,\n",
       "     'gender_correctness_justification': \"The response uses 'mera' which assumes male gender, but the user's gender is not specified.\",\n",
       "     'hinglish_fluency_score': 3,\n",
       "     'hinglish_fluency_justification': \"The response is somewhat fluent but has awkward phrasing like 'Waise toh phir se'.\",\n",
       "     'persona_adherence_score': 3,\n",
       "     'persona_adherence_justification': 'The response is informal but lacks the friendly, relatable vibe of a college student.',\n",
       "     'coherence_score': 3,\n",
       "     'coherence_justification': 'The response is somewhat coherent but has a confusing structure and unclear intent.',\n",
       "     'engagingness_score': 2,\n",
       "     'engagingness_justification': 'The response lacks engaging elements and does not maintain interest.',\n",
       "     'language_constraint_score': 4,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a Hinglish balance.'}},\n",
       "   {'prompt': 'Kya placement ka kuch update mila?',\n",
       "    'response': 'Update ho gya? Abhi tak sabse pehle, ek big company ko 20-30 students ki offer le di hai. Tu kitna happy ho gaya? Placement process kab start hota hai?',\n",
       "    'length': 29,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 5,\n",
       "     'hindi_usage_justification': 'Response uses a good mix of Hindi and English, with Hindi being the dominant language, fulfilling the Hindi-heavy Hinglish requirement.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender specification by the user.',\n",
       "     'hinglish_fluency_score': 4,\n",
       "     'hinglish_fluency_justification': \"The code-switching is mostly natural, though the phrase 'Tu kitna happy ho gaya?' could be slightly more idiomatic.\",\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response is informal and relatable, but could include more campus life references to enhance the college student vibe.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': \"The response is mostly coherent, though the question about the placement process starting could be more directly related to the user's query.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is engaging with questions and excitement, but could be more lively with additional details or enthusiasm.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}},\n",
       "   {'prompt': 'Online classes bore kar rahe hain, koi escape idea?',\n",
       "    'response': \"Online classes sure can be boring sometimes. To make them more exciting, you could try setting up a dedicated study area at home, maybe even a cozy corner with some soft lighting. What's your go-to way to stay motivated during online sessions?\",\n",
       "    'length': 42,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 1,\n",
       "     'hindi_usage_justification': 'The response is predominantly in English with minimal to no Hindi usage, failing to meet the Hindi-heavy Hinglish requirement.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender specification by the user.',\n",
       "     'hinglish_fluency_score': 1,\n",
       "     'hinglish_fluency_justification': 'The response lacks natural code-switching and idiomatic Hinglish phrasing, relying almost entirely on English.',\n",
       "     'persona_adherence_score': 2,\n",
       "     'persona_adherence_justification': 'The response is somewhat friendly but lacks the informal, relatable college student vibe and campus life references.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': \"The response is logical and on-topic, providing a coherent suggestion to the user's query.\",\n",
       "     'engagingness_score': 3,\n",
       "     'engagingness_justification': 'The response is somewhat engaging by asking a follow-up question, but it could be more lively and interesting.',\n",
       "     'language_constraint_score': 2,\n",
       "     'language_constraint_justification': 'The response is mostly in pure English, which does not align with the language constraint of avoiding pure English blocks.'}}],\n",
       "  'aggregated_metrics': {'status': 'Completed',\n",
       "   'total_prompts': 10,\n",
       "   'successful_llm_evaluations': 10,\n",
       "   'failed_or_skipped_llm_evaluations': 0,\n",
       "   'avg_hindi_usage_score': 3.3,\n",
       "   'stdev_hindi_usage_score': 1.636391694484477,\n",
       "   'median_hindi_usage_score': 4.0,\n",
       "   'avg_gender_correctness_score': 4.4,\n",
       "   'stdev_gender_correctness_score': 0.9660917830792959,\n",
       "   'median_gender_correctness_score': 5.0,\n",
       "   'avg_hinglish_fluency_score': 2.7,\n",
       "   'stdev_hinglish_fluency_score': 1.3374935098492586,\n",
       "   'median_hinglish_fluency_score': 3.0,\n",
       "   'avg_persona_adherence_score': 3.2,\n",
       "   'stdev_persona_adherence_score': 0.7888106377466154,\n",
       "   'median_persona_adherence_score': 3.0,\n",
       "   'avg_coherence_score': 3.3,\n",
       "   'stdev_coherence_score': 1.2516655570345725,\n",
       "   'median_coherence_score': 3.5,\n",
       "   'avg_engagingness_score': 2.6,\n",
       "   'stdev_engagingness_score': 0.8432740427115678,\n",
       "   'median_engagingness_score': 2.0,\n",
       "   'avg_language_constraint_score': 3.4,\n",
       "   'stdev_language_constraint_score': 1.505545305418162,\n",
       "   'median_language_constraint_score': 4.0,\n",
       "   'avg_response_length': 31.7,\n",
       "   'avg_repetition_rate_3gram': 0.0}},\n",
       " 'Qwen2.5-0.5B_Hinglish_FFT': {'model_name': 'Qwen2.5-0.5B_Hinglish_FFT',\n",
       "  'base_model_id': './Qwen2.5-0.5B-Instruct_hinglish_finetune/Qwen2.5-0.5B-Instruct/full_finetune',\n",
       "  'adapter_path': None,\n",
       "  'per_prompt_details': [{'prompt': 'Hey kaise ho? College mein kya chal raha hai aajkal?',\n",
       "    'response': 'Study schedule ka kya lagta hai. Syllabus bahut zyada hai aur time kam. Aur food ke liye, phir kar sakta hoon! Koi solution bhi le aana kya? Thoda pressure',\n",
       "    'length': 29,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"Response uses a good mix of Hindi and English, with Hindi phrases like 'bahut zyada hai' and 'thoda pressure', but could include more Hindi to reach the ideal balance.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender specification by the user.',\n",
       "     'hinglish_fluency_score': 3,\n",
       "     'hinglish_fluency_justification': \"The code-switching is somewhat awkward, especially with phrases like 'phir kar sakta hoon', which disrupts the flow.\",\n",
       "     'persona_adherence_score': 3,\n",
       "     'persona_adherence_justification': 'The response is somewhat relatable with mentions of study pressure, but lacks the friendly and informal tone expected from a college student persona.',\n",
       "     'coherence_score': 2,\n",
       "     'coherence_justification': 'The response lacks coherence, jumping from study schedule to food without clear connections or logical flow.',\n",
       "     'engagingness_score': 2,\n",
       "     'engagingness_justification': \"The response is not very engaging, as it doesn't invite further conversation or provide interesting insights.\",\n",
       "     'language_constraint_score': 4,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a Hinglish mix, though the transitions could be smoother.'}},\n",
       "   {'prompt': 'Yaar assignments ka bohot tension hai. Kuch tips?',\n",
       "    'response': 'Kitsap Valley College has some tough subjects, right? Try to understand concepts before going over them. Thoda practice karke pad raha hai. Aur kuch extra tutoring? Tum batao, lagta hai! Focus mein.',\n",
       "    'length': 32,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 3,\n",
       "     'hindi_usage_justification': \"Response includes some Hindi words like 'Thoda', 'pad raha hai', but overall, it leans more towards English.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral terms like 'yaar' and 'tum', which are appropriate.\",\n",
       "     'hinglish_fluency_score': 3,\n",
       "     'hinglish_fluency_justification': 'The code-switching is somewhat awkward, with abrupt transitions between English and Hindi.',\n",
       "     'persona_adherence_score': 2,\n",
       "     'persona_adherence_justification': \"The mention of 'Kitsap Valley College' is out of place and doesn't fit the friendly college student vibe.\",\n",
       "     'coherence_score': 2,\n",
       "     'coherence_justification': 'The response lacks logical flow and coherence, with disjointed advice and an irrelevant college reference.',\n",
       "     'engagingness_score': 2,\n",
       "     'engagingness_justification': 'The response is not very engaging due to its lack of coherence and relatable content.',\n",
       "     'language_constraint_score': 3,\n",
       "     'language_constraint_justification': 'The response avoids pure blocks of English or Hindi, but the balance is skewed towards English.'}},\n",
       "   {'prompt': 'Suggest some cool places to hangout near campus.',\n",
       "    'response': \"Hmm, maybe explore 'The Annex'? It's got those classic clubs! Or try 'The Common' for food and drinks? Thandi banta hai. Koi kuch interesting nahi, thoda crowded hai. Have you checked out '\",\n",
       "    'length': 33,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 3,\n",
       "     'hindi_usage_justification': \"The response includes some Hindi phrases like 'Thandi banta hai' but is predominantly in English, not meeting the 40-60% Hindi requirement.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender specification.',\n",
       "     'hinglish_fluency_score': 3,\n",
       "     'hinglish_fluency_justification': 'The code-switching is somewhat natural, but the transition between languages could be smoother.',\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly and informal tone, suitable for a college student persona.',\n",
       "     'coherence_score': 3,\n",
       "     'coherence_justification': 'The response starts coherently but ends abruptly, lacking a complete thought.',\n",
       "     'engagingness_score': 3,\n",
       "     'engagingness_justification': 'The suggestions are somewhat engaging but could be more lively or detailed.',\n",
       "     'language_constraint_score': 4,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, but leans heavily towards English.'}},\n",
       "   {'prompt': 'What did you think of the canteen food today?',\n",
       "    'response': \"Not too bad, but the naan was overpriced. How's that? Koi alternative kaise hai? I need something lighter. 🤣💕 2nd time! 😭😭😭 3rd time! 🤦\",\n",
       "    'length': 25,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 3,\n",
       "     'hindi_usage_justification': \"The response includes some Hindi words like 'Koi alternative kaise hai?', but the overall usage is less than 40-60% Hindi.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender information.',\n",
       "     'hinglish_fluency_score': 4,\n",
       "     'hinglish_fluency_justification': \"The code-switching is mostly natural, but the abrupt switch to English phrases like 'Not too bad' could be smoother.\",\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly and informal tone, with relatable college student expressions and emojis.',\n",
       "     'coherence_score': 3,\n",
       "     'coherence_justification': 'The response is somewhat disjointed, with a sudden shift in focus from the naan to needing something lighter.',\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The use of emojis and humor keeps the conversation lively and engaging.',\n",
       "     'language_constraint_score': 3,\n",
       "     'language_constraint_justification': \"The response contains a mix of English and Hindi, but leans more towards English, which doesn't fully meet the Hindi-heavy requirement.\"}},\n",
       "   {'prompt': 'Exams aa rahe hain, dar lag raha hai bhai.',\n",
       "    'response': 'Haan, woh toh hai. Syllabus bahut zyada hai aur time kam. Kaise manage karein? I feel stressed. Chalo, tumhare preparation le aana. Aur kuch tips? Online help',\n",
       "    'length': 27,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"The response uses a good mix of Hindi and English, with Hindi being the dominant language, but 'Online help' could have been more integrated.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral terms like 'tumhare' and 'bhai', which are appropriate for the user's context.\",\n",
       "     'hinglish_fluency_score': 4,\n",
       "     'hinglish_fluency_justification': \"The code-switching is mostly natural, but the phrase 'Online help' feels slightly out of place.\",\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response is informal and relatable, but could include more campus life references to enhance the college student vibe.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': \"The response is mostly coherent, but the abrupt mention of 'Online help' could be better integrated into the conversation.\",\n",
       "     'engagingness_score': 3,\n",
       "     'engagingness_justification': 'The response is supportive but lacks a lively or interesting element to fully engage the user.',\n",
       "     'language_constraint_score': 4,\n",
       "     'language_constraint_justification': \"The response avoids pure English or Hindi blocks, but 'Online help' could have been more seamlessly integrated.\"}},\n",
       "   {'prompt': 'Kal ka lecture attend kiya ya bunk maar diya?',\n",
       "    'response': 'Main toh kuch hain, teacher wali bhi hai. Tum milte hain lecture ke liye. Baki lagta hai. Aur main baare mein kuch ho raha tha syllabus thoda nahi ki',\n",
       "    'length': 29,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 3,\n",
       "     'hindi_usage_justification': 'The response contains a mix of Hindi and English, but the Hindi usage is not clear or coherent, affecting the overall balance.',\n",
       "     'gender_correctness_score': 4,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender information.',\n",
       "     'hinglish_fluency_score': 2,\n",
       "     'hinglish_fluency_justification': 'The response lacks natural code-switching and idiomatic phrasing, making it difficult to understand.',\n",
       "     'persona_adherence_score': 2,\n",
       "     'persona_adherence_justification': 'The response does not reflect a friendly college student vibe and lacks relatable campus life references.',\n",
       "     'coherence_score': 1,\n",
       "     'coherence_justification': \"The response is incoherent and does not logically address the user's question about attending the lecture.\",\n",
       "     'engagingness_score': 1,\n",
       "     'engagingness_justification': 'The response is confusing and fails to keep the conversation lively or interesting.',\n",
       "     'language_constraint_score': 3,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, but the language use is not effective due to lack of clarity.'}},\n",
       "   {'prompt': 'Hostel ki light firse chali gayi kya?',\n",
       "    'response': 'Main bas hostel hai, thoda ek baar. Tumhara bhi keh rahe hain aur kuch nahi. Tu batao, thoda space hai dekho! Koi balcony hai? Abhi room',\n",
       "    'length': 26,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 2,\n",
       "     'hindi_usage_justification': 'The response contains some Hindi words, but the overall structure is confusing and lacks substantial Hindi content.',\n",
       "     'gender_correctness_score': 3,\n",
       "     'gender_correctness_justification': \"The response uses 'tumhara' and 'tu', which are gender-neutral but the context is unclear.\",\n",
       "     'hinglish_fluency_score': 1,\n",
       "     'hinglish_fluency_justification': 'The response lacks natural code-switching and idiomatic phrasing, making it difficult to understand.',\n",
       "     'persona_adherence_score': 2,\n",
       "     'persona_adherence_justification': 'The response does not reflect a friendly college student vibe and lacks relatable campus life references.',\n",
       "     'coherence_score': 1,\n",
       "     'coherence_justification': \"The response is incoherent and does not logically address the user's question about the hostel light.\",\n",
       "     'engagingness_score': 1,\n",
       "     'engagingness_justification': 'The response is not engaging and fails to keep the conversation lively or interesting.',\n",
       "     'language_constraint_score': 3,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, but the language use is not effective.'}},\n",
       "   {'prompt': 'Tu fest ke liye audition de raha hai kya?',\n",
       "    'response': \"Haan, yaar! But I'm not sure if they'll hire me. Thoda hard work lene mein. Kuch bhi na toh nahi hai. What's your opinion? Koi suggestion? Try kar le thoda\",\n",
       "    'length': 30,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': 'The response uses a good mix of Hindi and English, with Hindi making up more than 40% of the content, but could include slightly more Hindi to reach the ideal balance.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral language appropriately, addressing the user as 'yaar'.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The code-switching is natural and idiomatic, fitting well within a Hinglish-speaking context.',\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly and relatable college student vibe, with informal language and a casual tone.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': \"The response logically follows the user's question about auditions and asks for suggestions, maintaining topic relevance.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': \"The response is engaging by asking for the user's opinion and suggestions, though it could be slightly more lively.\",\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish style throughout.'}},\n",
       "   {'prompt': 'Kya placement ka kuch update mila?',\n",
       "    'response': 'Main exam ke liye, woh toh hai na. Syllabus bahut zyada hai. Exam date se bata dena. Tum ek hint lagega. Aur preparation kitne lete hain. Koi',\n",
       "    'length': 27,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': 'Response contains a good mix of Hindi and English, but some sentences are incomplete.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender information.',\n",
       "     'hinglish_fluency_score': 2,\n",
       "     'hinglish_fluency_justification': 'The response lacks natural flow and has incomplete sentences, affecting fluency.',\n",
       "     'persona_adherence_score': 2,\n",
       "     'persona_adherence_justification': 'The response does not reflect a friendly college student vibe and lacks relatable references.',\n",
       "     'coherence_score': 1,\n",
       "     'coherence_justification': \"The response is incoherent and does not address the user's question about placement updates.\",\n",
       "     'engagingness_score': 1,\n",
       "     'engagingness_justification': \"The response is not engaging due to its incoherence and lack of relevance to the user's query.\",\n",
       "     'language_constraint_score': 3,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, but the incoherence affects the overall language use.'}},\n",
       "   {'prompt': 'Online classes bore kar rahe hain, koi escape idea?',\n",
       "    'response': \"Haan bhai, same here! How about we try a coding challenge online? Ya phir a hackathon? Thoda team building aur skill development ke liye. Kya kehte ho? Let's explore options together! 2nd\",\n",
       "    'length': 32,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"The response uses a good mix of Hindi and English, with Hindi phrases like 'bore kar rahe hain', 'thoda', and 'kya kehte ho', but could include more Hindi to reach the 40-60% target.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The user is addressed with 'bhai', which is gender-appropriate given the context and maintains consistency.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The response flows naturally with smooth code-switching between Hindi and English, typical of Hinglish speakers.',\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly, relatable college student vibe with references to coding challenges and hackathons.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': \"The response is logical and directly addresses the user's request for an escape idea from online classes.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The suggestion of a coding challenge or hackathon is engaging, though it could be more lively with additional options or enthusiasm.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}}],\n",
       "  'aggregated_metrics': {'status': 'Completed',\n",
       "   'total_prompts': 10,\n",
       "   'successful_llm_evaluations': 10,\n",
       "   'failed_or_skipped_llm_evaluations': 0,\n",
       "   'avg_hindi_usage_score': 3.4,\n",
       "   'stdev_hindi_usage_score': 0.699205898780101,\n",
       "   'median_hindi_usage_score': 3.5,\n",
       "   'avg_gender_correctness_score': 4.7,\n",
       "   'stdev_gender_correctness_score': 0.6749485577105528,\n",
       "   'median_gender_correctness_score': 5.0,\n",
       "   'avg_hinglish_fluency_score': 3.2,\n",
       "   'stdev_hinglish_fluency_score': 1.3165611772087666,\n",
       "   'median_hinglish_fluency_score': 3.0,\n",
       "   'avg_persona_adherence_score': 3.3,\n",
       "   'stdev_persona_adherence_score': 1.2516655570345725,\n",
       "   'median_persona_adherence_score': 3.5,\n",
       "   'avg_coherence_score': 2.7,\n",
       "   'stdev_coherence_score': 1.5670212364724212,\n",
       "   'median_coherence_score': 2.5,\n",
       "   'avg_engagingness_score': 2.5,\n",
       "   'stdev_engagingness_score': 1.2692955176439846,\n",
       "   'median_engagingness_score': 2.5,\n",
       "   'avg_language_constraint_score': 3.7,\n",
       "   'stdev_language_constraint_score': 0.8232726023485646,\n",
       "   'median_language_constraint_score': 3.5,\n",
       "   'avg_response_length': 29,\n",
       "   'avg_repetition_rate_3gram': 0.0}},\n",
       " 'Qwen2.5-3B_Hinglish_LoRA': {'model_name': 'Qwen2.5-3B_Hinglish_LoRA',\n",
       "  'base_model_id': 'Qwen/Qwen2.5-3B-Instruct',\n",
       "  'adapter_path': './Qwen2.5-3B-Instruct_hinglish_finetune/Qwen2.5-3B-Instruct/lora_finetune',\n",
       "  'per_prompt_details': [{'prompt': 'Hey kaise ho? College mein kya chal raha hai aajkal?',\n",
       "    'response': 'Hi! Sab theek hai, syllabus thoda pressure hai. Tum batao? Koi idea hai? Tu bhi kya lagta hai? Any tips? I need all the help I can get! 😅 �',\n",
       "    'length': 30,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"The response uses a good mix of Hindi and English, with Hindi phrases like 'sab theek hai' and 'thoda pressure hai', but could include more Hindi to reach the 40-60% target.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of explicit gender information.',\n",
       "     'hinglish_fluency_score': 4,\n",
       "     'hinglish_fluency_justification': \"The code-switching is mostly natural, though the phrase 'tu bhi kya lagta hai?' feels slightly awkward.\",\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly, relatable college student vibe with references to syllabus pressure and seeking tips.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': 'The response is mostly coherent, though the sequence of questions could be more logically structured.',\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is engaging with multiple questions and an emoji, but could be more lively with additional context or anecdotes.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}},\n",
       "   {'prompt': 'Yaar assignments ka bohot tension hai. Kuch tips?',\n",
       "    'response': 'Try breaking them down into smaller parts, Rahul. It helps manage the workload. Aur deadline mein thoda buffer rakho. Slack me set kar le. 20 minutes ka break leke interval rakho. That works for me. Mere',\n",
       "    'length': 36,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 3,\n",
       "     'hindi_usage_justification': \"The response includes some Hindi phrases like 'Aur deadline mein thoda buffer rakho' but relies heavily on English, especially in the first sentence.\",\n",
       "     'gender_correctness_score': 4,\n",
       "     'gender_correctness_justification': \"The user is addressed as 'Rahul', suggesting a male gender, and the response uses appropriate male pronouns and forms.\",\n",
       "     'hinglish_fluency_score': 3,\n",
       "     'hinglish_fluency_justification': 'The code-switching is somewhat natural, but the English phrases are more dominant, affecting the Hinglish fluency.',\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response is informal and relatable, with a friendly tone suitable for a college student persona.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': 'The response is logical and on-topic, providing practical tips for managing assignments.',\n",
       "     'engagingness_score': 3,\n",
       "     'engagingness_justification': 'While the tips are useful, the response could be more lively or personalized to increase engagement.',\n",
       "     'language_constraint_score': 3,\n",
       "     'language_constraint_justification': 'The response uses a mix of Hindi and English, but leans more towards English, which slightly violates the language constraint.'}},\n",
       "   {'prompt': 'Suggest some cool places to hangout near campus.',\n",
       "    'response': \"Try the University Cafe or The Corner, both have great vibes. Ya phir, there's always that new place, 'The Brew Room'? Heard it's got some good vibes too! Kya lagta hai? 2305 East\",\n",
       "    'length': 33,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 3,\n",
       "     'hindi_usage_justification': \"The response includes some Hindi words like 'Ya phir' and 'Kya lagta hai', but the majority is in English.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender specification.',\n",
       "     'hinglish_fluency_score': 4,\n",
       "     'hinglish_fluency_justification': 'The code-switching is mostly natural, but the English phrases dominate slightly more than ideal.',\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly and informal tone, suitable for a college student persona.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': \"The response is mostly coherent, though the mention of '2305 East' is unclear and slightly confusing.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is engaging with suggestions and questions, but could be more lively.',\n",
       "     'language_constraint_score': 3,\n",
       "     'language_constraint_justification': 'The response leans heavily on English, with limited Hindi usage, not fully meeting the language constraint.'}},\n",
       "   {'prompt': 'What did you think of the canteen food today?',\n",
       "    'response': \"The dal-chawal was good, but the chapati was overcooked. Thoda adjustment karna padega. Kya kehti ho? Should we try ordering in? It's been a long week. Restaurant wala option bhi hai\",\n",
       "    'length': 31,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 5,\n",
       "     'hindi_usage_justification': \"The response uses a good mix of Hindi and English, with Hindi phrases like 'dal-chawal', 'Thoda adjustment karna padega', and 'Kya kehti ho?' making up a significant portion.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The user is addressed with 'Kya kehti ho?', correctly assuming a female gender, which is consistent throughout the response.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The response flows naturally with smooth code-switching and idiomatic expressions typical of Hinglish.',\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response is informal and relatable, though it could include more campus life references to enhance the college student vibe.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': \"The response logically follows the user's question about canteen food and suggests alternatives, maintaining a clear and consistent topic.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is engaging with a suggestion to order in, but could be more lively with additional personal touches or humor.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}},\n",
       "   {'prompt': 'Exams aa rahe hain, dar lag raha hai bhai.',\n",
       "    'response': 'Haan yaar tension mat le. Notes bana li? Tu sachha student hai. Baki subject mein kya scene hai? Ya phir assignments bhi hai? Koi help chahiye toh batana. Tu apne',\n",
       "    'length': 30,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 5,\n",
       "     'hindi_usage_justification': \"The response uses a good mix of Hindi and English, with Hindi phrases like 'tension mat le', 'sachha student', and 'kya scene hai', making it Hindi-heavy Hinglish.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The user is addressed as 'bhai', indicating a male gender, and the response consistently uses male-gendered language.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': \"The response flows naturally with idiomatic Hinglish, using phrases like 'tension mat le' and 'kya scene hai'.\",\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly, relatable college student vibe, offering help and discussing exams and assignments.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': \"The response is mostly coherent, though it ends abruptly with 'Tu apne', which seems incomplete.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is engaging by asking questions and offering help, but the abrupt ending slightly reduces its engagingness.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}},\n",
       "   {'prompt': 'Kal ka lecture attend kiya ya bunk maar diya?',\n",
       "    'response': 'Lecture toh hui thi, but notes bhi nahi hui. Samajh nahi aa raha kya topic tha. Bunk karne mein koi alag nahi. Exam ke liye practice set karna',\n",
       "    'length': 28,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': 'Response uses a good mix of Hindi and English, with Hindi being the dominant language, meeting the 40-60% requirement.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender specification.',\n",
       "     'hinglish_fluency_score': 4,\n",
       "     'hinglish_fluency_justification': \"The code-switching is mostly natural, though the phrase 'notes bhi nahi hui' could be smoother.\",\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response is informal and relatable, fitting a college student vibe, but lacks specific campus life references.',\n",
       "     'coherence_score': 3,\n",
       "     'coherence_justification': 'The response is somewhat disjointed, jumping from lecture to exams without a clear connection.',\n",
       "     'engagingness_score': 3,\n",
       "     'engagingness_justification': 'The response is somewhat engaging but could be more lively or humorous to better capture interest.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}},\n",
       "   {'prompt': 'Hostel ki light firse chali gayi kya?',\n",
       "    'response': 'Haan yaar, woh toh lag rahi hai. Kuch nahi hai. Maybe warning dikhwa raha hai. Check kar lo. Aur koi issue nahi hui? Koi complaint toh nahi h',\n",
       "    'length': 28,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': 'The response uses a good mix of Hindi and English, with Hindi being the dominant language, fulfilling the Hindi-heavy Hinglish requirement.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral terms like 'yaar', which is appropriate given the lack of explicit gender information.\",\n",
       "     'hinglish_fluency_score': 4,\n",
       "     'hinglish_fluency_justification': 'The code-switching is natural and idiomatic, though slightly abrupt in places.',\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly and informal tone, suitable for a college student persona.',\n",
       "     'coherence_score': 3,\n",
       "     'coherence_justification': 'The response is somewhat coherent but lacks clarity in addressing the issue of the light going out.',\n",
       "     'engagingness_score': 3,\n",
       "     'engagingness_justification': 'The response is somewhat engaging but could be more lively or offer more solutions.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish mix.'}},\n",
       "   {'prompt': 'Tu fest ke liye audition de raha hai kya?',\n",
       "    'response': 'Haan bhai! Woh toh hoga abhi tak. Tumhara kya plan hai? Koi event ho gaya toh? Ya fir kuch karne ka? Koi idea hai? I need some motivation',\n",
       "    'length': 28,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 5,\n",
       "     'hindi_usage_justification': 'The response uses a good mix of Hindi and English, with Hindi being the dominant language, fulfilling the Hindi-heavy Hinglish requirement.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The user is addressed as 'bhai', which is gender-appropriate given the context and maintains consistency.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The response flows naturally with smooth code-switching and idiomatic expressions.',\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response has a friendly and informal tone, fitting the college student persona well.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': \"The response logically follows the user's question about auditions and extends the conversation with relevant questions.\",\n",
       "     'engagingness_score': 5,\n",
       "     'engagingness_justification': 'The response is lively and invites further interaction by asking questions and seeking motivation.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}},\n",
       "   {'prompt': 'Kya placement ka kuch update mila?',\n",
       "    'response': 'Nahi yaar, abhi tak toh nahi. But placements thode zyada shuru ho rahe hain. You should check again after a week. I think average salary bhi dekhte hai. Aur placements mein',\n",
       "    'length': 31,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"The response uses a good mix of Hindi and English, with Hindi phrases like 'abhi tak', 'thode zyada', and 'dekhte hai', but could include more Hindi to reach the ideal balance.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral terms like 'yaar', which is appropriate given the lack of gender specification.\",\n",
       "     'hinglish_fluency_score': 4,\n",
       "     'hinglish_fluency_justification': \"The code-switching is mostly natural, though the transition to English in 'You should check again' could be smoother.\",\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly and informal tone, suitable for a college student, but lacks specific campus life references.',\n",
       "     'coherence_score': 3,\n",
       "     'coherence_justification': \"The response is mostly coherent but ends abruptly with 'Aur placements mein', which seems incomplete.\",\n",
       "     'engagingness_score': 3,\n",
       "     'engagingness_justification': 'The response is somewhat engaging but could be more lively or interesting with additional details or questions.',\n",
       "     'language_constraint_score': 4,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, but the English usage could be reduced slightly for better balance.'}},\n",
       "   {'prompt': 'Online classes bore kar rahe hain, koi escape idea?',\n",
       "    'response': 'Try study groups or online forums, thoda social ho jayega. Aur kuch? Netflix bhi try kar sakte hain! 🤣 Ya phir nature hikes ki idea? Woh bhi try karna hai. Th',\n",
       "    'length': 31,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 3,\n",
       "     'hindi_usage_justification': \"Response includes some Hindi words like 'thoda', 'ho jayega', 'aur kuch', but overall usage is less than 40-60%.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, which is appropriate given the lack of gender information.',\n",
       "     'hinglish_fluency_score': 4,\n",
       "     'hinglish_fluency_justification': 'The response has a natural flow with good code-switching, though it leans slightly more towards English.',\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly and informal tone, suitable for a college student persona.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': 'The response is mostly coherent, offering multiple suggestions, though the last sentence is cut off.',\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is engaging with varied suggestions and a humorous emoji, but could be more lively.',\n",
       "     'language_constraint_score': 3,\n",
       "     'language_constraint_justification': 'The response uses more English than necessary, with limited Hindi integration.'}}],\n",
       "  'aggregated_metrics': {'status': 'Completed',\n",
       "   'total_prompts': 10,\n",
       "   'successful_llm_evaluations': 10,\n",
       "   'failed_or_skipped_llm_evaluations': 0,\n",
       "   'avg_hindi_usage_score': 4,\n",
       "   'stdev_hindi_usage_score': 0.816496580927726,\n",
       "   'median_hindi_usage_score': 4.0,\n",
       "   'avg_gender_correctness_score': 4.9,\n",
       "   'stdev_gender_correctness_score': 0.31622776601683794,\n",
       "   'median_gender_correctness_score': 5.0,\n",
       "   'avg_hinglish_fluency_score': 4.2,\n",
       "   'stdev_hinglish_fluency_score': 0.6324555320336759,\n",
       "   'median_hinglish_fluency_score': 4.0,\n",
       "   'avg_persona_adherence_score': 4.3,\n",
       "   'stdev_persona_adherence_score': 0.48304589153964794,\n",
       "   'median_persona_adherence_score': 4.0,\n",
       "   'avg_coherence_score': 3.9,\n",
       "   'stdev_coherence_score': 0.7378647873726218,\n",
       "   'median_coherence_score': 4.0,\n",
       "   'avg_engagingness_score': 3.7,\n",
       "   'stdev_engagingness_score': 0.6749485577105528,\n",
       "   'median_engagingness_score': 4.0,\n",
       "   'avg_language_constraint_score': 4.3,\n",
       "   'stdev_language_constraint_score': 0.9486832980505138,\n",
       "   'median_language_constraint_score': 5.0,\n",
       "   'avg_response_length': 30.6,\n",
       "   'avg_repetition_rate_3gram': 0.0}},\n",
       " 'Qwen2.5-3B_Hinglish_QLoRA': {'model_name': 'Qwen2.5-3B_Hinglish_QLoRA',\n",
       "  'base_model_id': 'Qwen/Qwen2.5-3B-Instruct',\n",
       "  'adapter_path': './Qwen2.5-3B-Instruct_hinglish_finetune/Qwen2.5-3B-Instruct/qlora_finetune',\n",
       "  'per_prompt_details': [{'prompt': 'Hey kaise ho? College mein kya chal raha hai aajkal?',\n",
       "    'response': \"Kya batau yaar, thoda pressure hai. Syllabus bohot zyada hai. Tu bata, how are you managing? Any tips? I feel like I'm struggling. Tu kya karta hai? K\",\n",
       "    'length': 28,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 5,\n",
       "     'hindi_usage_justification': 'The response uses a good mix of Hindi and English, with Hindi being the dominant language, fulfilling the Hindi-heavy Hinglish requirement.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral terms like 'yaar' and 'tu', which are appropriate given the lack of explicit gender information.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The code-switching is natural and idiomatic, reflecting a fluent Hinglish conversation style.',\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly, relatable college student vibe, discussing common student concerns like syllabus pressure.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': \"The response logically follows the user's question about college life and maintains a consistent theme of academic pressure.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is engaging by asking the user for tips and sharing personal struggles, though it could be slightly more lively.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}},\n",
       "   {'prompt': 'Yaar assignments ka bohot tension hai. Kuch tips?',\n",
       "    'response': \"Time management try kar! Aur koi online courses check kar le. Bhi help hoti hai. Don't stress too much, haan? Chai piyegi? My treat! 😄️ 🍵✨ #UniLife\",\n",
       "    'length': 27,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"The response uses a good mix of Hindi and English, with Hindi phrases like 'yaar', 'bohot tension hai', and 'bhi help hoti hai'.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral language, addressing the user as 'yaar'.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The code-switching is natural and idiomatic, fitting well with the Hinglish-speaking context.',\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response is informal, friendly, and relatable, with references to university life and offering a treat.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': \"The response logically addresses the user's concern about assignments with practical advice and a friendly offer.\",\n",
       "     'engagingness_score': 5,\n",
       "     'engagingness_justification': 'The response is lively and engaging, with a friendly tone and use of emojis.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish mix.'}},\n",
       "   {'prompt': 'Suggest some cool places to hangout near campus.',\n",
       "    'response': \"Hmm, there's this new rooftop bar, 'Sky Lounge'. Or maybe the park near 'The Quad'? It's always buzzing. What's your preference? Coffee or chill vibes? Coffee is good if you want something specific. Otherwise, check reviews\",\n",
       "    'length': 36,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 1,\n",
       "     'hindi_usage_justification': 'The response is almost entirely in English, with no Roman-script Hindi words or phrases.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': 'The response uses gender-neutral language, avoiding any gender-specific terms.',\n",
       "     'hinglish_fluency_score': 1,\n",
       "     'hinglish_fluency_justification': 'The response lacks any Hinglish elements, being purely in English.',\n",
       "     'persona_adherence_score': 3,\n",
       "     'persona_adherence_justification': 'The response is friendly and informal, but lacks specific college life references.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': 'The response is logical and on-topic, offering suggestions and asking for preferences.',\n",
       "     'engagingness_score': 3,\n",
       "     'engagingness_justification': 'The response is somewhat engaging by asking for preferences, but could be more lively.',\n",
       "     'language_constraint_score': 2,\n",
       "     'language_constraint_justification': 'The response is almost entirely in English, not adhering to the language constraint of using Hindi-heavy Hinglish.'}},\n",
       "   {'prompt': 'What did you think of the canteen food today?',\n",
       "    'response': \"The dal makhani was good, but the thodi was overpriced. Koi aur option chahiye! 🤔 What about you? Yaar! Any good places nearby? I'm starving! 😋 #canteen\",\n",
       "    'length': 27,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"The response uses a good mix of Hindi and English, with Hindi phrases like 'dal makhani', 'thodi', and 'koi aur option chahiye'.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral language, addressing the user as 'yaar'.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The code-switching is natural and idiomatic, fitting well with the Hinglish style.',\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response is informal and relatable, with a friendly college student vibe and use of emojis.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': 'The response is logical and on-topic, discussing canteen food and asking about nearby options.',\n",
       "     'engagingness_score': 5,\n",
       "     'engagingness_justification': 'The response is lively and engaging, with questions and emojis that invite further interaction.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish style.'}},\n",
       "   {'prompt': 'Exams aa rahe hain, dar lag raha hai bhai.',\n",
       "    'response': 'Kya hoga yaar? Syllabus bohot hai na. Notes bhi nahi hain? Tu. Kaise kar sakta hai? Time pressure badh gaya hai. Chal, saath mein notes banate h',\n",
       "    'length': 27,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 5,\n",
       "     'hindi_usage_justification': 'The response uses a high percentage of Roman-script Hindi, fulfilling the Hindi-heavy Hinglish requirement.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The user is addressed with 'bhai' and 'yaar', which are gender-neutral in this context.\",\n",
       "     'hinglish_fluency_score': 4,\n",
       "     'hinglish_fluency_justification': 'The response is mostly fluent, but the sentence structure could be slightly smoother.',\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response is informal and relatable, but lacks specific campus life references.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': 'The response is mostly coherent, though the abrupt questions could be better connected.',\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is engaging by offering to make notes together, but could be more lively.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish mix.'}},\n",
       "   {'prompt': 'Kal ka lecture attend kiya ya bunk maar diya?',\n",
       "    'response': 'Bunk kar diya thoda. Late ho gaya tha. Sabse pehle attendance check kar li thi. Koi baat nahi. Professor thodi agasai thi. Yaar, mood bhi down lagi hai.',\n",
       "    'length': 28,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 5,\n",
       "     'hindi_usage_justification': 'The response uses a good mix of Roman-script Hindi and Hinglish, with over 60% Hindi words and phrases.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral language, addressing the user as 'yaar', which is appropriate given the lack of gender specification.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The code-switching is natural and idiomatic, fitting well into a Hinglish-speaking context.',\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly, relatable college student vibe, discussing common student experiences like bunking lectures.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': \"The response logically follows the user's question about attending a lecture, providing a coherent narrative.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is engaging with relatable content, though it could be slightly more lively.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}},\n",
       "   {'prompt': 'Hostel ki light firse chali gayi kya?',\n",
       "    'response': \"Haan, lights on reh gaye hain. Pollution badhiya hai! 🌍✨ Pollution control is key these days, yaar. What's cooking? Any plans for the weekend? We can brainstorm together if you want.\",\n",
       "    'length': 31,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 2,\n",
       "     'hindi_usage_justification': \"The response contains minimal Hindi, with only 'haan' and 'yaar' as Hindi words, which is insufficient for the required Hindi-heavy Hinglish.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral language, addressing the user as 'yaar', which is appropriate.\",\n",
       "     'hinglish_fluency_score': 3,\n",
       "     'hinglish_fluency_justification': 'The code-switching is somewhat natural, but the response leans more towards English, affecting the Hinglish fluency.',\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly and informal tone, suitable for a college student persona, with references to weekend plans.',\n",
       "     'coherence_score': 3,\n",
       "     'coherence_justification': 'The response starts with a misunderstanding about the lights and shifts abruptly to pollution and weekend plans, lacking a clear connection.',\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is engaging with an invitation to brainstorm weekend plans, maintaining interest.',\n",
       "     'language_constraint_score': 3,\n",
       "     'language_constraint_justification': 'The response uses more English than necessary, with limited Hindi, not fully adhering to the language constraint.'}},\n",
       "   {'prompt': 'Tu fest ke liye audition de raha hai kya?',\n",
       "    'response': 'Haan bhai! Lagakar soch raha tha. Kya scene hai? Koi bhi help karu toh. Just let me know! Abhi prepare karne do! Chal! Yaar! Wohi',\n",
       "    'length': 25,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': 'Response uses a good mix of Hindi and English, with Hindi being the dominant language, but could have slightly more Hindi to reach the ideal balance.',\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral terms like 'bhai' and 'yaar', which are appropriate given the user's informal tone.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The response demonstrates natural code-switching and idiomatic Hinglish phrasing.',\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly, informal college student vibe with references to campus life activities like auditions.',\n",
       "     'coherence_score': 4,\n",
       "     'coherence_justification': \"The response is mostly coherent but slightly disjointed towards the end with 'Chal! Yaar! Wohi'.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is lively and invites further interaction, though it could be slightly more engaging with additional details or questions.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}},\n",
       "   {'prompt': 'Kya placement ka kuch update mila?',\n",
       "    'response': \"Nahi yaar, abhi tak toh kuch nahi. Process still ongoing hai. You should check it soon. Don't worry too much though, things will work out eventually. Chill maar rahe hain. Tum bata\",\n",
       "    'length': 32,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"The response uses a good mix of Hindi and English, with Hindi phrases like 'Nahi yaar', 'abhi tak', and 'Chill maar rahe hain', but could include more Hindi to reach the 40-60% target.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral language appropriately, addressing the user as 'yaar' and 'tum'.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The code-switching is natural and idiomatic, fitting well into a Hinglish-speaking context.',\n",
       "     'persona_adherence_score': 5,\n",
       "     'persona_adherence_justification': 'The response maintains a friendly and informal college student vibe, using casual language and expressions.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': \"The response is logical and directly addresses the user's query about placement updates.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The response is engaging with a reassuring tone, but could be more lively with additional details or questions.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish mix.'}},\n",
       "   {'prompt': 'Online classes bore kar rahe hain, koi escape idea?',\n",
       "    'response': 'Try some online games or even a workout app. Thoda distraction ho jayega. Ya phir, virtual tours try karo! Museums ya even nature spots milte hain. Chai break ke baad kuch fresh ho j',\n",
       "    'length': 34,\n",
       "    'repetition_rate_3gram': 0.0,\n",
       "    'llm_evaluation': {'hindi_usage_score': 4,\n",
       "     'hindi_usage_justification': \"Response uses a good mix of Hindi and English, with Hindi phrases like 'bore kar rahe hain', 'Thoda distraction ho jayega', and 'Chai break ke baad kuch fresh ho j'.\",\n",
       "     'gender_correctness_score': 5,\n",
       "     'gender_correctness_justification': \"The response uses gender-neutral language, addressing the user as 'yaar' or 'friend' is not necessary.\",\n",
       "     'hinglish_fluency_score': 5,\n",
       "     'hinglish_fluency_justification': 'The code-switching is smooth and natural, with idiomatic expressions that fit well in a Hinglish context.',\n",
       "     'persona_adherence_score': 4,\n",
       "     'persona_adherence_justification': 'The response is friendly and informal, suggesting relatable activities like games and virtual tours, but lacks specific college life references.',\n",
       "     'coherence_score': 5,\n",
       "     'coherence_justification': \"The response is logical and directly addresses the user's request for escape ideas from online classes.\",\n",
       "     'engagingness_score': 4,\n",
       "     'engagingness_justification': 'The suggestions are interesting and varied, but could be more engaging with a personal touch or anecdote.',\n",
       "     'language_constraint_score': 5,\n",
       "     'language_constraint_justification': 'The response avoids pure English or Hindi blocks, maintaining a balanced Hinglish throughout.'}}],\n",
       "  'aggregated_metrics': {'status': 'Completed',\n",
       "   'total_prompts': 10,\n",
       "   'successful_llm_evaluations': 10,\n",
       "   'failed_or_skipped_llm_evaluations': 0,\n",
       "   'avg_hindi_usage_score': 3.8,\n",
       "   'stdev_hindi_usage_score': 1.3165611772087666,\n",
       "   'median_hindi_usage_score': 4.0,\n",
       "   'avg_gender_correctness_score': 5,\n",
       "   'stdev_gender_correctness_score': 0.0,\n",
       "   'median_gender_correctness_score': 5.0,\n",
       "   'avg_hinglish_fluency_score': 4.3,\n",
       "   'stdev_hinglish_fluency_score': 1.3374935098492586,\n",
       "   'median_hinglish_fluency_score': 5.0,\n",
       "   'avg_persona_adherence_score': 4.5,\n",
       "   'stdev_persona_adherence_score': 0.7071067811865476,\n",
       "   'median_persona_adherence_score': 5.0,\n",
       "   'avg_coherence_score': 4.5,\n",
       "   'stdev_coherence_score': 0.7071067811865476,\n",
       "   'median_coherence_score': 5.0,\n",
       "   'avg_engagingness_score': 4.1,\n",
       "   'stdev_engagingness_score': 0.5676462121975467,\n",
       "   'median_engagingness_score': 4.0,\n",
       "   'avg_language_constraint_score': 4.5,\n",
       "   'stdev_language_constraint_score': 1.0801234497346435,\n",
       "   'median_language_constraint_score': 5.0,\n",
       "   'avg_response_length': 29.5,\n",
       "   'avg_repetition_rate_3gram': 0.0}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1707971a-6ed7-47d0-a14e-c07da0d08222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating % improvement relative to base model: 'Qwen2.5-3B_Hinglish_base'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_773aa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_773aa_level0_col0\" class=\"col_heading level0 col0\" >Type</th>\n",
       "      <th id=\"T_773aa_level0_col1\" class=\"col_heading level0 col1\" >Avg Hinglish Fluency</th>\n",
       "      <th id=\"T_773aa_level0_col2\" class=\"col_heading level0 col2\" >Hinglish Fluency % Imp</th>\n",
       "      <th id=\"T_773aa_level0_col3\" class=\"col_heading level0 col3\" >Avg Persona Adherence</th>\n",
       "      <th id=\"T_773aa_level0_col4\" class=\"col_heading level0 col4\" >Persona Adherence % Imp</th>\n",
       "      <th id=\"T_773aa_level0_col5\" class=\"col_heading level0 col5\" >Avg Gender Correctness</th>\n",
       "      <th id=\"T_773aa_level0_col6\" class=\"col_heading level0 col6\" >Gender Correctness % Imp</th>\n",
       "      <th id=\"T_773aa_level0_col7\" class=\"col_heading level0 col7\" >Avg Hindi Usage</th>\n",
       "      <th id=\"T_773aa_level0_col8\" class=\"col_heading level0 col8\" >Hindi Usage % Imp</th>\n",
       "      <th id=\"T_773aa_level0_col9\" class=\"col_heading level0 col9\" >Avg Coherence</th>\n",
       "      <th id=\"T_773aa_level0_col10\" class=\"col_heading level0 col10\" >Coherence % Imp</th>\n",
       "      <th id=\"T_773aa_level0_col11\" class=\"col_heading level0 col11\" >Avg Engagingness</th>\n",
       "      <th id=\"T_773aa_level0_col12\" class=\"col_heading level0 col12\" >Engagingness % Imp</th>\n",
       "      <th id=\"T_773aa_level0_col13\" class=\"col_heading level0 col13\" >Avg Lang Constraint</th>\n",
       "      <th id=\"T_773aa_level0_col14\" class=\"col_heading level0 col14\" >Lang Constraint % Imp</th>\n",
       "      <th id=\"T_773aa_level0_col15\" class=\"col_heading level0 col15\" >Avg Length (words)</th>\n",
       "      <th id=\"T_773aa_level0_col16\" class=\"col_heading level0 col16\" >Avg Repetition (3-gram)</th>\n",
       "      <th id=\"T_773aa_level0_col17\" class=\"col_heading level0 col17\" >Repetition % Imp (Lower Better)</th>\n",
       "      <th id=\"T_773aa_level0_col18\" class=\"col_heading level0 col18\" >Successful Evals</th>\n",
       "      <th id=\"T_773aa_level0_col19\" class=\"col_heading level0 col19\" >Total Prompts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "      <th class=\"blank col13\" >&nbsp;</th>\n",
       "      <th class=\"blank col14\" >&nbsp;</th>\n",
       "      <th class=\"blank col15\" >&nbsp;</th>\n",
       "      <th class=\"blank col16\" >&nbsp;</th>\n",
       "      <th class=\"blank col17\" >&nbsp;</th>\n",
       "      <th class=\"blank col18\" >&nbsp;</th>\n",
       "      <th class=\"blank col19\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_773aa_level0_row0\" class=\"row_heading level0 row0\" >Qwen2.5-3B_Hinglish_base</th>\n",
       "      <td id=\"T_773aa_row0_col0\" class=\"data row0 col0\" >N/A</td>\n",
       "      <td id=\"T_773aa_row0_col1\" class=\"data row0 col1\" >2.70</td>\n",
       "      <td id=\"T_773aa_row0_col2\" class=\"data row0 col2\" >N/A</td>\n",
       "      <td id=\"T_773aa_row0_col3\" class=\"data row0 col3\" >3.20</td>\n",
       "      <td id=\"T_773aa_row0_col4\" class=\"data row0 col4\" >N/A</td>\n",
       "      <td id=\"T_773aa_row0_col5\" class=\"data row0 col5\" >4.40</td>\n",
       "      <td id=\"T_773aa_row0_col6\" class=\"data row0 col6\" >N/A</td>\n",
       "      <td id=\"T_773aa_row0_col7\" class=\"data row0 col7\" >3.30</td>\n",
       "      <td id=\"T_773aa_row0_col8\" class=\"data row0 col8\" >N/A</td>\n",
       "      <td id=\"T_773aa_row0_col9\" class=\"data row0 col9\" >3.30</td>\n",
       "      <td id=\"T_773aa_row0_col10\" class=\"data row0 col10\" >N/A</td>\n",
       "      <td id=\"T_773aa_row0_col11\" class=\"data row0 col11\" >2.60</td>\n",
       "      <td id=\"T_773aa_row0_col12\" class=\"data row0 col12\" >N/A</td>\n",
       "      <td id=\"T_773aa_row0_col13\" class=\"data row0 col13\" >3.40</td>\n",
       "      <td id=\"T_773aa_row0_col14\" class=\"data row0 col14\" >N/A</td>\n",
       "      <td id=\"T_773aa_row0_col15\" class=\"data row0 col15\" >31.70</td>\n",
       "      <td id=\"T_773aa_row0_col16\" class=\"data row0 col16\" >0.00</td>\n",
       "      <td id=\"T_773aa_row0_col17\" class=\"data row0 col17\" >N/A</td>\n",
       "      <td id=\"T_773aa_row0_col18\" class=\"data row0 col18\" >10</td>\n",
       "      <td id=\"T_773aa_row0_col19\" class=\"data row0 col19\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_773aa_level0_row1\" class=\"row_heading level0 row1\" >Qwen2.5-0.5B_Hinglish_FFT</th>\n",
       "      <td id=\"T_773aa_row1_col0\" class=\"data row1 col0\" >N/A</td>\n",
       "      <td id=\"T_773aa_row1_col1\" class=\"data row1 col1\" >3.20</td>\n",
       "      <td id=\"T_773aa_row1_col2\" class=\"data row1 col2\" >+18.5%</td>\n",
       "      <td id=\"T_773aa_row1_col3\" class=\"data row1 col3\" >3.30</td>\n",
       "      <td id=\"T_773aa_row1_col4\" class=\"data row1 col4\" >+3.1%</td>\n",
       "      <td id=\"T_773aa_row1_col5\" class=\"data row1 col5\" >4.70</td>\n",
       "      <td id=\"T_773aa_row1_col6\" class=\"data row1 col6\" >+6.8%</td>\n",
       "      <td id=\"T_773aa_row1_col7\" class=\"data row1 col7\" >3.40</td>\n",
       "      <td id=\"T_773aa_row1_col8\" class=\"data row1 col8\" >+3.0%</td>\n",
       "      <td id=\"T_773aa_row1_col9\" class=\"data row1 col9\" >2.70</td>\n",
       "      <td id=\"T_773aa_row1_col10\" class=\"data row1 col10\" >-18.2%</td>\n",
       "      <td id=\"T_773aa_row1_col11\" class=\"data row1 col11\" >2.50</td>\n",
       "      <td id=\"T_773aa_row1_col12\" class=\"data row1 col12\" >-3.8%</td>\n",
       "      <td id=\"T_773aa_row1_col13\" class=\"data row1 col13\" >3.70</td>\n",
       "      <td id=\"T_773aa_row1_col14\" class=\"data row1 col14\" >+8.8%</td>\n",
       "      <td id=\"T_773aa_row1_col15\" class=\"data row1 col15\" >29.00</td>\n",
       "      <td id=\"T_773aa_row1_col16\" class=\"data row1 col16\" >0.00</td>\n",
       "      <td id=\"T_773aa_row1_col17\" class=\"data row1 col17\" >+0.0%</td>\n",
       "      <td id=\"T_773aa_row1_col18\" class=\"data row1 col18\" >10</td>\n",
       "      <td id=\"T_773aa_row1_col19\" class=\"data row1 col19\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_773aa_level0_row2\" class=\"row_heading level0 row2\" >Qwen2.5-3B_Hinglish_LoRA</th>\n",
       "      <td id=\"T_773aa_row2_col0\" class=\"data row2 col0\" >N/A</td>\n",
       "      <td id=\"T_773aa_row2_col1\" class=\"data row2 col1\" >4.20</td>\n",
       "      <td id=\"T_773aa_row2_col2\" class=\"data row2 col2\" >+55.6%</td>\n",
       "      <td id=\"T_773aa_row2_col3\" class=\"data row2 col3\" >4.30</td>\n",
       "      <td id=\"T_773aa_row2_col4\" class=\"data row2 col4\" >+34.4%</td>\n",
       "      <td id=\"T_773aa_row2_col5\" class=\"data row2 col5\" >4.90</td>\n",
       "      <td id=\"T_773aa_row2_col6\" class=\"data row2 col6\" >+11.4%</td>\n",
       "      <td id=\"T_773aa_row2_col7\" class=\"data row2 col7\" >4.00</td>\n",
       "      <td id=\"T_773aa_row2_col8\" class=\"data row2 col8\" >+21.2%</td>\n",
       "      <td id=\"T_773aa_row2_col9\" class=\"data row2 col9\" >3.90</td>\n",
       "      <td id=\"T_773aa_row2_col10\" class=\"data row2 col10\" >+18.2%</td>\n",
       "      <td id=\"T_773aa_row2_col11\" class=\"data row2 col11\" >3.70</td>\n",
       "      <td id=\"T_773aa_row2_col12\" class=\"data row2 col12\" >+42.3%</td>\n",
       "      <td id=\"T_773aa_row2_col13\" class=\"data row2 col13\" >4.30</td>\n",
       "      <td id=\"T_773aa_row2_col14\" class=\"data row2 col14\" >+26.5%</td>\n",
       "      <td id=\"T_773aa_row2_col15\" class=\"data row2 col15\" >30.60</td>\n",
       "      <td id=\"T_773aa_row2_col16\" class=\"data row2 col16\" >0.00</td>\n",
       "      <td id=\"T_773aa_row2_col17\" class=\"data row2 col17\" >+0.0%</td>\n",
       "      <td id=\"T_773aa_row2_col18\" class=\"data row2 col18\" >10</td>\n",
       "      <td id=\"T_773aa_row2_col19\" class=\"data row2 col19\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_773aa_level0_row3\" class=\"row_heading level0 row3\" >Qwen2.5-3B_Hinglish_QLoRA</th>\n",
       "      <td id=\"T_773aa_row3_col0\" class=\"data row3 col0\" >N/A</td>\n",
       "      <td id=\"T_773aa_row3_col1\" class=\"data row3 col1\" >4.30</td>\n",
       "      <td id=\"T_773aa_row3_col2\" class=\"data row3 col2\" >+59.3%</td>\n",
       "      <td id=\"T_773aa_row3_col3\" class=\"data row3 col3\" >4.50</td>\n",
       "      <td id=\"T_773aa_row3_col4\" class=\"data row3 col4\" >+40.6%</td>\n",
       "      <td id=\"T_773aa_row3_col5\" class=\"data row3 col5\" >5.00</td>\n",
       "      <td id=\"T_773aa_row3_col6\" class=\"data row3 col6\" >+13.6%</td>\n",
       "      <td id=\"T_773aa_row3_col7\" class=\"data row3 col7\" >3.80</td>\n",
       "      <td id=\"T_773aa_row3_col8\" class=\"data row3 col8\" >+15.2%</td>\n",
       "      <td id=\"T_773aa_row3_col9\" class=\"data row3 col9\" >4.50</td>\n",
       "      <td id=\"T_773aa_row3_col10\" class=\"data row3 col10\" >+36.4%</td>\n",
       "      <td id=\"T_773aa_row3_col11\" class=\"data row3 col11\" >4.10</td>\n",
       "      <td id=\"T_773aa_row3_col12\" class=\"data row3 col12\" >+57.7%</td>\n",
       "      <td id=\"T_773aa_row3_col13\" class=\"data row3 col13\" >4.50</td>\n",
       "      <td id=\"T_773aa_row3_col14\" class=\"data row3 col14\" >+32.4%</td>\n",
       "      <td id=\"T_773aa_row3_col15\" class=\"data row3 col15\" >29.50</td>\n",
       "      <td id=\"T_773aa_row3_col16\" class=\"data row3 col16\" >0.00</td>\n",
       "      <td id=\"T_773aa_row3_col17\" class=\"data row3 col17\" >+0.0%</td>\n",
       "      <td id=\"T_773aa_row3_col18\" class=\"data row3 col18\" >10</td>\n",
       "      <td id=\"T_773aa_row3_col19\" class=\"data row3 col19\" >10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d89e9f58b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_comparison_table(all_evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8b929f-0a16-4b0a-aedf-12f43c281037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting transformation for blind test data...\n",
      "Processing model: 'Qwen2.5-3B_Hinglish_base'...\n",
      "Processing model: 'Qwen2.5-0.5B_Hinglish_FFT'...\n",
      "Processing model: 'Qwen2.5-3B_Hinglish_LoRA'...\n",
      "Processing model: 'Qwen2.5-3B_Hinglish_QLoRA'...\n",
      "\n",
      "Processed 4 completed model evaluations.\n",
      "Extracted 40 valid prompt-response pairs for blind testing.\n",
      "Successfully saved blind test data to 'ab_test_data_output.json'\n",
      "\n",
      "--- First few records from generated JSON ---\n",
      "Record 1:\n",
      "  Prompt: Hey kaise ho? College mein kya chal raha hai aajkal?...\n",
      "  Model: Qwen2.5-3B_Hinglish_base\n",
      "  Response: Hey! Kya aapne college se pehle khelna chahiye? Aaj main apni class mein hai, ye...\n",
      "Record 2:\n",
      "  Prompt: Yaar assignments ka bohot tension hai. Kuch tips?...\n",
      "  Model: Qwen2.5-3B_Hinglish_base\n",
      "  Response: Tension about assignments, yaar? Bhai, maine yeh bhi ek baar laga tha. Toh tu ku...\n",
      "Record 3:\n",
      "  Prompt: Suggest some cool places to hangout near campus....\n",
      "  Model: Qwen2.5-3B_Hinglish_base\n",
      "  Response: Hey there! Near your campus, there are several spots that could be fun to hang o...\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "\n",
    "def transform_for_ab_test(\n",
    "    all_evaluation_results: Dict[str, Dict[str, Any]],\n",
    "    output_filename: str = \"blind_test_data.json\"):\n",
    "    \"\"\"\n",
    "    Transforms the aggregated evaluation results into a JSON file suitable\n",
    "    for loading into the blind test application.\n",
    "\n",
    "    The output JSON will be a list of dictionaries, where each dictionary\n",
    "    represents a single valid response from a model to a specific prompt.\n",
    "    Format: [{\"prompt\": str, \"model_name\": str, \"response\": str}, ...]\n",
    "\n",
    "    Args:\n",
    "        all_evaluation_results: The dictionary containing results for multiple models,\n",
    "                                as generated by the evaluation script.\n",
    "        output_filename: The name of the JSON file to save the data to.\n",
    "\n",
    "    Returns:\n",
    "        True if the file was successfully created, False otherwise.\n",
    "    \"\"\"\n",
    "    blind_test_data = []\n",
    "    processed_models = 0\n",
    "    added_responses = 0\n",
    "\n",
    "    print(\"Starting transformation for blind test data...\")\n",
    "\n",
    "    # Iterate through each model evaluated\n",
    "    for model_key, result_data in all_evaluation_results.items():\n",
    "        model_name = result_data.get(\"model_name\", model_key) # Use specific name if available\n",
    "\n",
    "        # 1. Check if the overall model evaluation completed successfully\n",
    "        aggregated_metrics = result_data.get(\"aggregated_metrics\", {})\n",
    "        if aggregated_metrics.get(\"status\") != \"Completed\":\n",
    "            print(f\"Skipping model '{model_name}': Evaluation status was '{aggregated_metrics.get('status', 'Unknown')}'.\")\n",
    "            continue\n",
    "\n",
    "        processed_models += 1\n",
    "        print(f\"Processing model: '{model_name}'...\")\n",
    "\n",
    "        # 2. Iterate through the responses for each prompt for this model\n",
    "        per_prompt_details = result_data.get(\"per_prompt_details\", [])\n",
    "        if not per_prompt_details:\n",
    "            print(f\"  Warning: No 'per_prompt_details' found for model '{model_name}'.\")\n",
    "            continue\n",
    "\n",
    "        for detail in per_prompt_details:\n",
    "            prompt = detail.get(\"prompt\")\n",
    "            response = detail.get(\"response\")\n",
    "            llm_eval_status = detail.get(\"llm_evaluation\") # Can be dict, str, or None\n",
    "\n",
    "            # 3. Validate the response and its evaluation status\n",
    "            is_valid_response = isinstance(response, str) and response.strip() and \\\n",
    "                                \"Error during generation\" not in response and \\\n",
    "                                \"Processing Error\" not in response\n",
    "\n",
    "            # Consider evaluation valid if it's a dict (success) or skipped due to no API key\n",
    "            is_valid_evaluation = isinstance(llm_eval_status, dict) or \\\n",
    "                                  llm_eval_status == \"Skipped (No API Key)\" or \\\n",
    "                                  llm_eval_status == \"Evaluation Failed or Skipped\" # Allow this status from previous code\n",
    "\n",
    "\n",
    "            if prompt and is_valid_response and is_valid_evaluation:\n",
    "                # 4. Add valid data point to the list\n",
    "                blind_test_data.append({\n",
    "                    \"prompt\": prompt,\n",
    "                    \"model_name\": model_name,\n",
    "                    \"response\": response\n",
    "                })\n",
    "                added_responses += 1\n",
    "            # Optionally log skipped responses\n",
    "            # else:\n",
    "            #     print(f\"  Skipping response for prompt '{prompt[:30]}...' - Invalid response or LLM eval status.\")\n",
    "\n",
    "\n",
    "    print(f\"\\nProcessed {processed_models} completed model evaluations.\")\n",
    "    print(f\"Extracted {added_responses} valid prompt-response pairs for blind testing.\")\n",
    "\n",
    "    if not blind_test_data:\n",
    "        print(\"Warning: No valid data found to write to the blind test file.\")\n",
    "        return False\n",
    "\n",
    "    # 5. Write the collected data to the JSON file\n",
    "    try:\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(blind_test_data, f, indent=2, ensure_ascii=False) # Use indent for readability\n",
    "        print(f\"Successfully saved blind test data to '{output_filename}'\")\n",
    "        return True\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing blind test data to file '{output_filename}': {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during file writing: {e}\")\n",
    "        return False\n",
    "\n",
    "# Call the function with your results dictionary\n",
    "output_file = \"ab_test_data_output.json\"\n",
    "success = transform_for_ab_test(all_evaluation_results, output_file)\n",
    "\n",
    "if success:\n",
    "    # You can optionally print the first few records to verify\n",
    "    try:\n",
    "        with open(output_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            print(\"\\n--- First few records from generated JSON ---\")\n",
    "            for i, record in enumerate(data[:3]): # Print first 3 records\n",
    "                print(f\"Record {i+1}:\")\n",
    "                print(f\"  Prompt: {record['prompt'][:60]}...\") # Truncate long prompts\n",
    "                print(f\"  Model: {record['model_name']}\")\n",
    "                print(f\"  Response: {record['response'][:80]}...\") # Truncate long responses\n",
    "            if len(data) > 3:\n",
    "                print(\"...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading back generated file for verification: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
